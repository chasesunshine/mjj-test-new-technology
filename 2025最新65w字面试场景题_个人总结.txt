# 2. 电商平台中订单未支付过期如何实现自动关单？
## 定时任务 (个人不建议)
优点：
    实现容易，成本低，基本不依赖其他组件。
缺点：
    时间可能不够精确。由于定时任务扫描的间隔是固定的，所以可能造成一些订单已经过期了一段时间才被扫描到，订单关闭的时间比正常时间晚一些。
    增加了数据库的压力。随着订单的数量越来越多，扫描的成本也会越来越大，执行时间也会被拉长，可能导致某些应该被关闭的订单迟迟没有被关闭。
总结：
    采用定时任务的方案比较适合对时间要求不是很敏感，并且数据量不太多的业务场景。
## JDK 延迟队列 DelayQueue
    DelayQueue 是 JDK 提供的一个无界队列，我们可以看到，DelayQueue 队列中的元素需要实现 Delayed，它只提供了一个方法，就是获取过期时间
    用户的订单生成以后，设置过期时间比如 30 分钟，放入定义好的 DelayQueue，然后创建一个线程，在线程中通过 while(true)不断的从 DelayQueue 中获取过期的数据。
    优点：
        不依赖任何第三方组件，连数据库也不需要了，实现起来也方便。
    缺点：
        因为 DelayQueue 是一个无界队列，如果放入的订单过多，会造成 JVMOOM。DelayQueue 基于 JVM 内存，如果 JVM 重启了，那所有数据就丢失了。
    总结：
        DelayQueue 适用于数据量较小，且丢失也不影响主业务的场景，比如内部系统的一些非重要通知，就算丢失，也不会有太大影响
个人解惑:
    while(true)不断的从 DelayQueue 中获取过期的数据。用的是@PostConstruct之类的方案做处理
## redis 过期监听
    redis 是一个高性能的 KV 数据库，除了用作缓存以外，其实还提供了过期监听的功能。在 redis.conf 中，配置 notify-keyspace-events Ex 即可开启此功能。
    然后在代码中继承 KeyspaceEventMessageListener，实现 onMessage 就可以监听过期的数据量。
    优点：
        由于redis的高性能，所以我们在设置key，或者消费key时，速度上是可以保证的。
    缺点：
        由于redis的key过期策略原因，当一个key过期时，redis无法保证立刻将其删除，自然我们的监听事件也无法第一时间消费到这个key，所以会存在一定的延迟。
        另外，在redis5.0之前，订阅发布中的消息并没有被持久化，自然也没有所谓的确认机制。所以一旦消费消息的过程中我们的客户端发生了宕机，这条消息就彻底丢失了。
    总结：
        redis 的过期订阅相比于其他方案没有太大的优势，在实际生产环境中，用得相对较少。
## Redisson 分布式延迟队列
    Redisson 是一个基于 redis 实现的 Java 驻内存数据网格，它不仅提供了一系列的分布式的 Java 常用对象，还提供了许多分布式服务。
    Redisson 除了提供我们常用的分布式锁外，还提供了一个分布式延迟队列RDelayedQueue，他是一种基于 zset 结构实现的延迟队列，其实现类是RedissonDelayedQueue。
    优点：
        使用简单，并且其实现类中大量使用 lua 脚本保证其原子性，不会有并发重复问题。
    缺点：
        需要依赖 redis（如果这算一种缺点的话）。
    总结：
        Redisson 是 redis 官方推荐的 JAVA 客户端，提供了很多常用的功能，使用简单、高效，推荐大家尝试使用
## RocketMQ 延迟消息
    延迟消息，当消息写入到 Broker 后，不会立刻被消费者消费，需要等待指定的时长后才可被消费处理的消息，称为延时消息。
    在订单创建之后，我们就可以把订单作为一条消息投递到 rocketmq，并将延迟时间设置为 30 分钟，这样，30 分钟后我们定义的 consumer 就可以消费到这条消息，然后检查用户是否支付了这个订单
    优点：
        可以使代码逻辑清晰，系统之间完全解耦，只需关注生产及消费消息即可。另外其吞吐量极高，最多可以支撑万亿级的数据量。
    缺点：
        相对来说 mq 是重量级的组件，引入 mq 之后，随之而来的消息丢失、幂等性问题等都加深了系统的复杂度。
    总结：
        通过 mq 进行系统业务解耦，以及对系统性能削峰填谷已经是当前高性能系统的标配。
## RabbitMQ 死信队列
    除了 RocketMQ 的延迟队列，RabbitMQ 的死信队列也可以实现消息延迟功能。当 RabbitMQ 中的一条正常消息，因为过了存活时间（TTL 过期）、队列长度超限、被消费者拒绝等原因无法被消费时，就会被当成一条死信消息，投递到死信队列。
    基于这样的机制，我们可以给消息设置一个 ttl，然后故意不消费消息，等消息过期就会进入死信队列，我们再消费死信队列即可。通过这样的方式，就可以达到同 RocketMQ 延迟消息一样的效果。
    优点：
        同 RocketMQ 一样，RabbitMQ 同样可以使业务解耦，基于其集群的扩展性，也可以实现高可用、高性能的目标。
    缺点：
        死信队列本质还是一个队列，队列都是先进先出，如果队头的消息过期时间比较长，就会导致后面过期的消息无法得到及时消费，造成消息阻塞。
    总结：
        除了增加系统复杂度之外，死信队列的阻塞问题也是需要我们重点关注的。

# 3. 如何设计一个秒杀系统
    在我看来，秒杀系统本质上就是一个满足大并发、高性能和高可用的分布式系统
    在我看来，秒杀其实主要解决两个问题，一个是并发读，一个是并发写。
## 3.3.4 处理热点数据
    处理热点数据通常有几种思路：一是优化，二是限制，三是隔离。
    先来说说优化。优化热点数据最有效的办法就是缓存热点数据，如果热点数据做了动静分离，那么可以长期缓存静态数据。但是，缓存热点数据更多的是“临时”缓存，即不管是静态数据还是动态数据，都用一个队列短暂地缓存数秒钟，由于队列长度有限，可以采用 LRU 淘汰算法替换
    再来说说限制。限制更多的是一种保护机制，限制的办法也有很多，例如对被访问商品的 ID 做一致性 Hash，然后根据 Hash 做分桶，每个分桶设置一个处理队列，这样可以把热点商品限制在一个请求队列里，防止因某些热点商品占用太多的服务器资源，而使其他请求始终得不到服务器的处理资源。
    最后介绍一下隔离。秒杀系统设计的第一个原则就是将这种热点数据隔离出来，不要让1%的请求影响到另外的 99%，隔离出来后也更方便对这 1%的请求做针对性的优化。具体到“秒杀”业务，我们可以在以下几个层次实现隔离。
        1. 业务隔离。把秒杀做成一种营销活动，卖家要参加秒杀这种营销活动需要单独报名，从技术上来说，卖家报名后对我们来说就有了已知热点，因此可以提前做好预热。
        2. 系统隔离。系统隔离更多的是运行时的隔离，可以通过分组部署的方式和另外 99%分开。秒杀可以申请单独的域名，目的也是让请求落到不同的集群中。
        3. 数据隔离。秒杀所调用的数据大部分都是热点数据，比如会启用单独的 Cache 集群或者 MySQL 数据库来放热点数据，目的也是不想 0.01%的数据有机会影响99.99%数据。

# 4. 如果你的系统的 QPS 突然提升 10 倍你会怎么设计？
## 4.1 硬件的扩展+微服务的拆分
## 4.2 高性能 RPC
    有小伙伴进行对比测试，Dubbo RPC 的性能，是 Feign RPC 的性能 10 倍。(这一点 mjj 本人提出质疑)
    mjj个人搜索解答：
        Dubbo RPC 在性能上优于 Feign RPC，主要原因包括以下几个方面：
        1. **协议与传输层优化**
           - **Dubbo** 默认采用 **Dubbo 协议**，基于 **TCP 长连接** 和 **Netty** 进行通信，减少了连接建立和断开的开销，适合高并发场景。
           - **Feign** 基于 **HTTP/1.1**（短连接），每次请求都需要建立和断开 TCP 连接，增加了网络开销，性能较低。
        2. **序列化方式**
           - **Dubbo** 支持 **Hessian2、Protobuf** 等高效的二进制序列化方式，数据体积小，解析速度快。
           - **Feign** 默认使用 **JSON/XML** 等文本格式，数据体积较大，解析效率较低。
        3. **通信模型**
           - **Dubbo** 支持 **异步调用** 和 **NIO（Netty）**，能更好地利用系统资源，提高吞吐量。
           - **Feign** 基于 **同步阻塞式 HTTP 调用**，在高并发场景下容易出现性能瓶颈。
        4. **负载均衡与容错机制**
           - **Dubbo** 内置 **多种负载均衡策略**（随机、轮询、最少活跃调用等），并支持 **服务端和客户端负载均衡**，减少网络延迟。
           - **Feign** 依赖 **Ribbon（或 Spring Cloud LoadBalancer）**，仅支持客户端负载均衡，策略相对较少。
        5. **服务治理优化**
           - **Dubbo** 提供 **更细粒度的流量控制**（如并发控制、超时管理），减少无效请求，提高整体性能。
           - **Feign** 的容错依赖 **Hystrix（已停止维护）** 或 **Sentinel**，相比 Dubbo 的 **Failover/Failfast 等策略**，性能优化空间较小。
        6. **网络层优化**
           - **Dubbo** 的 **RPC 协议** 属于 **传输层**，比 **Feign（应用层 HTTP）** 减少了协议解析的开销。
           - **Dubbo 支持多协议**（如 gRPC、RMI），可根据业务需求选择最优方案。
        **总结**
        Dubbo 在 **协议优化、序列化效率、通信模型、负载均衡、服务治理** 等方面均优于 Feign，因此在高并发、低延迟场景下性能更高。而 Feign 的优势在于 **易用性、RESTful 兼容性**，适合中小规模微服务架构。
## 4.3 消息队列消峰解耦
## 4.4 三级缓存架构
    以秒杀系统举例，活动预热商品信息可以提前缓存提供查询服务，库存数据可以提前缓存，下单流程可以完全走缓存扣减，秒杀结束后再异步写入数据库，数据库承担的压力就小的太多了。
## 4.5 数据库分库分表
    读写分离也就相当于数据库集群的方式降低了单节点的压力。而面对数据的急剧增长，原来的单库单表的存储方式已经无法支撑整个业务的发展，这时候就需要对数据库进行分库分表了。针对微服务而言垂直的分库本身已经是做过的，剩下大部分都是分表的方案了。
## 4.6 高可用
## 4.7 总结
   其实可以看到，怎么设计高并发系统这个问题本身他是不难的，无非是基于你知道的知识点，从物理硬件层面到软件的架构、代码层面的优化，使用什么中间件来不断提高系统的抗压能力。
   但是这个问题本身会带来更多的问题，微服务本身的拆分带来了分布式事务的问题，http、RPC 框架的使用带来了通信效率、路由、容错的问题，MQ 的引入带来了消息丢失、积压、事务消息、顺序消息的问题，
   缓存的引入又会带来一致性、雪崩、击穿的问题，数据库的读写分离、分库分表又会带来主从同步延迟、分布式 ID、事务一致性的问题，而为了解决这些问题我们又要不断的加入各种措施熔断、限流、降级、离线核对、预案处理等等来防止和追溯这些问题。

# 6. 如何从零搭建 10 万级 QPS 大流量、高并发优惠券系统
### 6.3.1 存储瓶颈及解决方案
    瓶颈：
        在系统架构中，我们使用了 MySQL、Redis 作为存储组件。我们知道，单个服务器的 I/O 能力终是有限的，在实际测试过程中，能够得到如下的数据：
         单个 MySQL 的每秒写入在 4000 QPS 左右，超过这个数字，MySQL 的I/O 时延会剧量增长。
         MySQL 单表记录到达了千万级别，查询效率会大大降低，如果过亿的话，数据查询会成为一个问题。
         Redis 单分片的写入瓶颈在 2w
    解决方案：
        1. 读写分离。在查询券模板、查询券记录等场景下，我们可以将 MySQL 进行读写分离，让这部分查询流量走 MySQL 的读库，从而减轻 MySQL 写库的查询压力。
        2. 分治。在软件设计中，有一种分治的思想，对于存储瓶颈的问题，业界常用的方案就是分而治之：流量分散、存储分散，即：分库分表。
        3. 发券，归根结底是要对用户的领券记录做持久化存储。对于 MySQL 本身 I/O瓶颈来说，我们可以在不同服务器上部署 MySQL 的不同分片，对 MySQL做水平扩容，这样一来，写请求就会分布在不同的 MySQL 主机上，这样就能够大幅提升 MySQL 整体的吞吐量。
        4. 给用户发了券，那么用户肯定需要查询自己获得的券。基于这个逻辑，我们以user_id 后四位为分片键，对用户领取的记录表做水平拆分，以支持用户维度的领券记录的查询。
        5. 每种券都有对应的数量，在给用户发券的过程中，我们是将发券数记录在Redis 中的，大流量的情况下，我们也需要对 Redis 做水平扩容，减轻 Redis单机的压力。

# 14. 如何避免超预期的高并发压力压垮系统？
    解决这种问题的一个主要手段就是限流，即拒绝部分访问请求，使访问负载压力降低到一个系统可以承受的程度。这样虽然有部分用户访问失败，但是整个系统依然是可用的，依然能对外提供服务，而不是因为负载压力太大而崩溃，导致所有用户都不能访问。为此，我们准备开发一个限流器，产品名称为“Diana”。
## 14.1 需求分析
    我们将 Diana 定位为一个限流器组件，即 Diana 的主要应用场景是部署在微服务网关或者其他 HTTP 服务器入口，以过滤器的方式对请求进行过滤，对超过限流规则的请求返回“服务不可用”HTTP 响应。
    Diana 的限流规则可通过配置文件获取，并需要支持本地配置和远程配置两种方式，远程配置优先于本地配置。限流方式包括：
         全局限流：针对所有请求进行限流，即保证整个系统处理的请求总数满足限流配置。
         账号限流：针对账号进行限流，即对单个账号发送的请求进行限流。
         设备限流：针对设备进行限流，即对单个客户端设备发送的请求进行限流。
         资源限流：针对某个资源（即某个 URL）进行限流，即保证访问该资源的请求总数满足限流配置。
    并且 Diana 设计应遵循开闭原则，能够支持灵活的限流规则功能扩展，即未来在不修改现有代码和兼容现有配置文件的情况下，支持新的配置规则。
### 14.2.2 高可用设计
   为了保证配置中心服务器和 Redis 服务器宕机时，限流器组件的高可用。限流器应具有自动降级功能，即配置中心不可用，则使用本地配置；Redis 服务器不可用，则降级为本地限流。
## 14.3 详细设计
    常用的限流算法有 4 种，
    固定窗口（Window）限流算法，滑动窗口（Sliding Window）限流算法，漏桶（Leaky Bucket）限流算法，令牌桶（Token Bucket）限流算法。

# 17. 如何让系统抗住双十一的预约抢购活动？
    我们先把需求梳理一下，总的来说，实现一个抢购系统大概可以分为四个阶段。
     商品预约：用户进入商品详情页面，获取购买资格，并等待商品抢购倒计时。
     等待抢购：等待商品抢购倒计时，直到商品开放抢购。
     商品抢购：商品抢购倒计时结束，用户提交抢购订单，排队等待抢购结果，抢购成功后，扣减系统库存，生成抢购订单。
     订单支付：等待用户支付成功后，系统更新订单状态，通知用户购买成功。
    接下来，我们就针对各阶段容易出现的问题，来分析其中的技术考点和解决方案
# 17.1 商品预约阶段
    那么问题来了：如何在高并发量的情况下，让每个用户都能得到抢购资格呢？这是预约抢购场景第一个技术考察点。 那你可以基于“06 | 分布式系统中，如何回答锁的实现原理？”来控制抢购资格的发放。
    我们基于 Redis 实现分布式锁（这是最常用的方式），在加锁的过程中，实际上是给Key 键设置一个值，为避免死锁，还要给
        SET lock_key unique_value NX PX 1000
     lock_key 就是 key 键；
     unique_value 是客户端生成的唯一的标识；
     NX 代表只在 lock_key 不存在时，才对 lock_key 进行设置操作；
     PX 10000 表示设置 lock_key 的过期时间为 10s，这是为了避免客户端发生异常而无法释放锁。
# 17.2 等待抢购阶段
    那么问题来了：如何解决等待抢购时间内的流量突增问题呢？有两个解决思路。
     页面静态化
     服务端限流
# 17.3 商品抢购阶段
    从“商品抢购阶段的架构设计”中我们可以总结出三个技术考点：流量削峰、扣减库存、分库分表。
# 17.4 订单支付阶段
    订单支付后操作（异常）
    所以你还要考虑“05 | 海量并发场景下，如何回答分布式事务一致性问题？”中，可靠消息投递机制：
    先做消息的本地存储，再通过异步重试机制，来实现消息的补偿。
    比如当支付平台回调订单系统，然后在更新状态的同时，插入一个消息，之后再返回第三方支付操作成功的结果。
    最后，通过数据库中的这条消息，再异步推送其他系统，完成后续的工作。
    mjj个人答疑解惑：(详见 SpringBoot订单支付后消息可靠补偿方案.md)
        SpringBoot订单支付后消息可靠补偿方案
        在订单支付后的操作中，发送异步消息到积分和短信服务时可能会遇到网络抖动、服务不可用等异常情况。下面提供一个完整的可靠消息补偿方案，包含本地消息表和异步重试机制。
            方案设计
            1. 本地消息表：在业务数据库中创建消息表，记录需要发送的消息
            2. 事务一致性：将业务操作和消息记录放在同一个事务中
            3. 定时任务：定期扫描未完成的消息进行重试
            4. 幂等处理：消费端需要实现幂等性，防止重复消费

# 18. 如果让你设计一个支持千万级流量的架构，你会怎么设计？
## 18.1 前端优化
    前端的优化主要有三个环节：减少请求次数、页面静态化、边缘计算。
        减少请求次数：减少前端脚本与后端服务的请求次数，有三种方案。
         增加缓存控制
         减少图像的请求次
         减少脚本的请求
## 18.2 后端优化
    后端环节的性能问题，可以从基础设施层面、网络层面、架构层面三个角度进行考量

# 19. 如何设计 RPC 框架在 10 万 QPS 下实现毫秒级的服务调用？
## 19.2 如何提升网络传输性能
    常见的五种 I/O 模型：
        同步阻塞 I/O；
        同步非阻塞 I/O；
        同步多路 I/O 复用；
        信号驱动 I/O；
        异步 I/O。
    你需要理解这五种 I/O 模型的区别和特点，不过在理解上你可能会有些难度，所以我来做个比喻方便你理解。
    我们把 I/O 过程比喻成烧水倒水的过程，等待资源（就是烧水的过程），使用资源（就是倒水的过程）：
        如果你站在灶台边上一直等着（等待资源）水烧开，然后倒水（使用资源），那么就是同步阻塞 I/O；
        如果你偷点儿懒，在烧水的时候躺在沙发上看会儿电视（不再时时刻刻等待资源），但是还是要时不时地去看看水开了没有，一旦水开了，马上去倒水（使用资源），那么这就是同步非阻塞 I/O；
        如果你想要洗澡，需要同时烧好多壶水，那你就在看电视的间隙去看看哪壶水开了（等待多个资源），哪一壶开了就先倒哪一壶，这样就加快了烧水的速度，这就是同步多路I/O 复用；
        不过你发现自己总是跑厨房去看水开了没，太累了，于是你考虑给你的水壶加一个报警器（信号），只要水开了就马上去倒水，这就是信号驱动 I/O；
        最后一种就高级了，你发明了一个智能水壶，在水烧好后自动就可以把水倒好，这就是异步 I/O。
    这五种 I/O 模型中最被广泛使用的是多路 I/O 复用，Linux 系统中的 select、epoll等系统调用都是支持多路 I/O 复用模型的，Java 中的高性能网络框架 Netty 默认也是使用这种模型。你可以选择它。
## 19.3 选择合适的序列化方式
    综合上面的几个考虑点，在我看来，我们的序列化备选方案主要有以下几种：
        首先是大家熟知的 JSON，它起源于 JavaScript 是一种最广泛使用的序列化协议，它的优势简单易用，同时在性能上相比 XML
        Thrift 是 Facebook 开源的高性能的序列化协议，也是一个轻量级的 RPC 框架；
        Protobuf 是谷歌开源的序列化协议。它们的共同特点是无论在空间上还是时间上都有着很高的性能，缺点就是由于 IDL 存在带来一些使用上的不方便
    那么你要如何选择这几种序列化协议呢？这里我给你几点建议：
    如果对于性能要求不高，在传输数据占用带宽不大的场景下可以使用 JSON 作为序列化协议；
    如果对于性能要求比较高，那么使用 Thrift 或者 Protobuf 都可以。而 Thrift 提供了配套的 RPC 框架，所以想要一体化的解决方案，你可以优先考虑 Thrift；
    在一些存储的场景下，比如说你的缓存中存储的数据占用空间较大，那么你可以考虑使用 Protobuf 替换 JSON

# 21. 如何根据应用场景选择合适的消息中间件？




# 目前看到51. [阿里一面]购物车系统怎么设计？