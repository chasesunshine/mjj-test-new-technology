# 2. 电商平台中订单未支付过期如何实现自动关单？
## 定时任务 (个人不建议)
优点：
    实现容易，成本低，基本不依赖其他组件。
缺点：
    时间可能不够精确。由于定时任务扫描的间隔是固定的，所以可能造成一些订单已经过期了一段时间才被扫描到，订单关闭的时间比正常时间晚一些。
    增加了数据库的压力。随着订单的数量越来越多，扫描的成本也会越来越大，执行时间也会被拉长，可能导致某些应该被关闭的订单迟迟没有被关闭。
总结：
    采用定时任务的方案比较适合对时间要求不是很敏感，并且数据量不太多的业务场景。
## JDK 延迟队列 DelayQueue
    DelayQueue 是 JDK 提供的一个无界队列，我们可以看到，DelayQueue 队列中的元素需要实现 Delayed，它只提供了一个方法，就是获取过期时间
    用户的订单生成以后，设置过期时间比如 30 分钟，放入定义好的 DelayQueue，然后创建一个线程，在线程中通过 while(true)不断的从 DelayQueue 中获取过期的数据。
    优点：
        不依赖任何第三方组件，连数据库也不需要了，实现起来也方便。
    缺点：
        因为 DelayQueue 是一个无界队列，如果放入的订单过多，会造成 JVMOOM。DelayQueue 基于 JVM 内存，如果 JVM 重启了，那所有数据就丢失了。
    总结：
        DelayQueue 适用于数据量较小，且丢失也不影响主业务的场景，比如内部系统的一些非重要通知，就算丢失，也不会有太大影响
个人解惑:
    while(true)不断的从 DelayQueue 中获取过期的数据。用的是@PostConstruct之类的方案做处理
## redis 过期监听
    redis 是一个高性能的 KV 数据库，除了用作缓存以外，其实还提供了过期监听的功能。在 redis.conf 中，配置 notify-keyspace-events Ex 即可开启此功能。
    然后在代码中继承 KeyspaceEventMessageListener，实现 onMessage 就可以监听过期的数据量。
    优点：
        由于redis的高性能，所以我们在设置key，或者消费key时，速度上是可以保证的。
    缺点：
        由于redis的key过期策略原因，当一个key过期时，redis无法保证立刻将其删除，自然我们的监听事件也无法第一时间消费到这个key，所以会存在一定的延迟。
        另外，在redis5.0之前，订阅发布中的消息并没有被持久化，自然也没有所谓的确认机制。所以一旦消费消息的过程中我们的客户端发生了宕机，这条消息就彻底丢失了。
    总结：
        redis 的过期订阅相比于其他方案没有太大的优势，在实际生产环境中，用得相对较少。
## Redisson 分布式延迟队列
    Redisson 是一个基于 redis 实现的 Java 驻内存数据网格，它不仅提供了一系列的分布式的 Java 常用对象，还提供了许多分布式服务。
    Redisson 除了提供我们常用的分布式锁外，还提供了一个分布式延迟队列RDelayedQueue，他是一种基于 zset 结构实现的延迟队列，其实现类是RedissonDelayedQueue。
    优点：
        使用简单，并且其实现类中大量使用 lua 脚本保证其原子性，不会有并发重复问题。
    缺点：
        需要依赖 redis（如果这算一种缺点的话）。
    总结：
        Redisson 是 redis 官方推荐的 JAVA 客户端，提供了很多常用的功能，使用简单、高效，推荐大家尝试使用
## RocketMQ 延迟消息
    延迟消息，当消息写入到 Broker 后，不会立刻被消费者消费，需要等待指定的时长后才可被消费处理的消息，称为延时消息。
    在订单创建之后，我们就可以把订单作为一条消息投递到 rocketmq，并将延迟时间设置为 30 分钟，这样，30 分钟后我们定义的 consumer 就可以消费到这条消息，然后检查用户是否支付了这个订单
    优点：
        可以使代码逻辑清晰，系统之间完全解耦，只需关注生产及消费消息即可。另外其吞吐量极高，最多可以支撑万亿级的数据量。
    缺点：
        相对来说 mq 是重量级的组件，引入 mq 之后，随之而来的消息丢失、幂等性问题等都加深了系统的复杂度。
    总结：
        通过 mq 进行系统业务解耦，以及对系统性能削峰填谷已经是当前高性能系统的标配。
## RabbitMQ 死信队列
    除了 RocketMQ 的延迟队列，RabbitMQ 的死信队列也可以实现消息延迟功能。当 RabbitMQ 中的一条正常消息，因为过了存活时间（TTL 过期）、队列长度超限、被消费者拒绝等原因无法被消费时，就会被当成一条死信消息，投递到死信队列。
    基于这样的机制，我们可以给消息设置一个 ttl，然后故意不消费消息，等消息过期就会进入死信队列，我们再消费死信队列即可。通过这样的方式，就可以达到同 RocketMQ 延迟消息一样的效果。
    优点：
        同 RocketMQ 一样，RabbitMQ 同样可以使业务解耦，基于其集群的扩展性，也可以实现高可用、高性能的目标。
    缺点：
        死信队列本质还是一个队列，队列都是先进先出，如果队头的消息过期时间比较长，就会导致后面过期的消息无法得到及时消费，造成消息阻塞。
    总结：
        除了增加系统复杂度之外，死信队列的阻塞问题也是需要我们重点关注的。

# 3. 如何设计一个秒杀系统
    在我看来，秒杀系统本质上就是一个满足大并发、高性能和高可用的分布式系统
    在我看来，秒杀其实主要解决两个问题，一个是并发读，一个是并发写。
## 3.3.4 处理热点数据
    处理热点数据通常有几种思路：一是优化，二是限制，三是隔离。
    先来说说优化。优化热点数据最有效的办法就是缓存热点数据，如果热点数据做了动静分离，那么可以长期缓存静态数据。但是，缓存热点数据更多的是“临时”缓存，即不管是静态数据还是动态数据，都用一个队列短暂地缓存数秒钟，由于队列长度有限，可以采用 LRU 淘汰算法替换
    再来说说限制。限制更多的是一种保护机制，限制的办法也有很多，例如对被访问商品的 ID 做一致性 Hash，然后根据 Hash 做分桶，每个分桶设置一个处理队列，这样可以把热点商品限制在一个请求队列里，防止因某些热点商品占用太多的服务器资源，
        而使其他请求始终得不到服务器的处理资源。
    最后介绍一下隔离。秒杀系统设计的第一个原则就是将这种热点数据隔离出来，不要让1%的请求影响到另外的 99%，隔离出来后也更方便对这 1%的请求做针对性的优化。具体到“秒杀”业务，我们可以在以下几个层次实现隔离。
        1. 业务隔离。把秒杀做成一种营销活动，卖家要参加秒杀这种营销活动需要单独报名，从技术上来说，卖家报名后对我们来说就有了已知热点，因此可以提前做好预热。
        2. 系统隔离。系统隔离更多的是运行时的隔离，可以通过分组部署的方式和另外 99%分开。秒杀可以申请单独的域名，目的也是让请求落到不同的集群中。
        3. 数据隔离。秒杀所调用的数据大部分都是热点数据，比如会启用单独的 Cache 集群或者 MySQL 数据库来放热点数据，目的也是不想 0.01%的数据有机会影响99.99%数据。

# 4. 如果你的系统的 QPS 突然提升 10 倍你会怎么设计？
## 4.1 硬件的扩展+微服务的拆分
## 4.2 高性能 RPC
    有小伙伴进行对比测试，Dubbo RPC 的性能，是 Feign RPC 的性能 10 倍。(这一点 mjj 本人提出质疑)
    mjj个人搜索解答：
        Dubbo RPC 在性能上优于 Feign RPC，主要原因包括以下几个方面：
        1. **协议与传输层优化**
           - **Dubbo** 默认采用 **Dubbo 协议**，基于 **TCP 长连接** 和 **Netty** 进行通信，减少了连接建立和断开的开销，适合高并发场景。
           - **Feign** 基于 **HTTP/1.1**（短连接），每次请求都需要建立和断开 TCP 连接，增加了网络开销，性能较低。
        2. **序列化方式**
           - **Dubbo** 支持 **Hessian2、Protobuf** 等高效的二进制序列化方式，数据体积小，解析速度快。
           - **Feign** 默认使用 **JSON/XML** 等文本格式，数据体积较大，解析效率较低。
        3. **通信模型**
           - **Dubbo** 支持 **异步调用** 和 **NIO（Netty）**，能更好地利用系统资源，提高吞吐量。
           - **Feign** 基于 **同步阻塞式 HTTP 调用**，在高并发场景下容易出现性能瓶颈。
        4. **负载均衡与容错机制**
           - **Dubbo** 内置 **多种负载均衡策略**（随机、轮询、最少活跃调用等），并支持 **服务端和客户端负载均衡**，减少网络延迟。
           - **Feign** 依赖 **Ribbon（或 Spring Cloud LoadBalancer）**，仅支持客户端负载均衡，策略相对较少。
        5. **服务治理优化**
           - **Dubbo** 提供 **更细粒度的流量控制**（如并发控制、超时管理），减少无效请求，提高整体性能。
           - **Feign** 的容错依赖 **Hystrix（已停止维护）** 或 **Sentinel**，相比 Dubbo 的 **Failover/Failfast 等策略**，性能优化空间较小。
        6. **网络层优化**
           - **Dubbo** 的 **RPC 协议** 属于 **传输层**，比 **Feign（应用层 HTTP）** 减少了协议解析的开销。
           - **Dubbo 支持多协议**（如 gRPC、RMI），可根据业务需求选择最优方案。
        **总结**
        Dubbo 在 **协议优化、序列化效率、通信模型、负载均衡、服务治理** 等方面均优于 Feign，因此在高并发、低延迟场景下性能更高。而 Feign 的优势在于 **易用性、RESTful 兼容性**，适合中小规模微服务架构。
## 4.3 消息队列消峰解耦
## 4.4 三级缓存架构
    以秒杀系统举例，活动预热商品信息可以提前缓存提供查询服务，库存数据可以提前缓存，下单流程可以完全走缓存扣减，秒杀结束后再异步写入数据库，数据库承担的压力就小的太多了。
## 4.5 数据库分库分表
    读写分离也就相当于数据库集群的方式降低了单节点的压力。而面对数据的急剧增长，原来的单库单表的存储方式已经无法支撑整个业务的发展，这时候就需要对数据库进行分库分表了。针对微服务而言垂直的分库本身已经是做过的，剩下大部分都是分表的方案了。
## 4.6 高可用
## 4.7 总结
   其实可以看到，怎么设计高并发系统这个问题本身他是不难的，无非是基于你知道的知识点，从物理硬件层面到软件的架构、代码层面的优化，使用什么中间件来不断提高系统的抗压能力。
   但是这个问题本身会带来更多的问题，微服务本身的拆分带来了分布式事务的问题，http、RPC 框架的使用带来了通信效率、路由、容错的问题，MQ 的引入带来了消息丢失、积压、事务消息、顺序消息的问题，
   缓存的引入又会带来一致性、雪崩、击穿的问题，数据库的读写分离、分库分表又会带来主从同步延迟、分布式 ID、事务一致性的问题，而为了解决这些问题我们又要不断的加入各种措施熔断、限流、降级、离线核对、预案处理等等来防止和追溯这些问题。

# 6. 如何从零搭建 10 万级 QPS 大流量、高并发优惠券系统
### 6.3.1 存储瓶颈及解决方案
    瓶颈：
        在系统架构中，我们使用了 MySQL、Redis 作为存储组件。我们知道，单个服务器的 I/O 能力终是有限的，在实际测试过程中，能够得到如下的数据：
         单个 MySQL 的每秒写入在 4000 QPS 左右，超过这个数字，MySQL 的I/O 时延会剧量增长。
         MySQL 单表记录到达了千万级别，查询效率会大大降低，如果过亿的话，数据查询会成为一个问题。
         Redis 单分片的写入瓶颈在 2w
    解决方案：
        1. 读写分离。在查询券模板、查询券记录等场景下，我们可以将 MySQL 进行读写分离，让这部分查询流量走 MySQL 的读库，从而减轻 MySQL 写库的查询压力。
        2. 分治。在软件设计中，有一种分治的思想，对于存储瓶颈的问题，业界常用的方案就是分而治之：流量分散、存储分散，即：分库分表。
        3. 发券，归根结底是要对用户的领券记录做持久化存储。对于 MySQL 本身 I/O瓶颈来说，我们可以在不同服务器上部署 MySQL 的不同分片，对 MySQL做水平扩容，这样一来，写请求就会分布在不同的 MySQL 主机上，这样就能够大幅提升 MySQL 整体的吞吐量。
        4. 给用户发了券，那么用户肯定需要查询自己获得的券。基于这个逻辑，我们以user_id 后四位为分片键，对用户领取的记录表做水平拆分，以支持用户维度的领券记录的查询。
        5. 每种券都有对应的数量，在给用户发券的过程中，我们是将发券数记录在Redis 中的，大流量的情况下，我们也需要对 Redis 做水平扩容，减轻 Redis单机的压力。

# 14. 如何避免超预期的高并发压力压垮系统？
    解决这种问题的一个主要手段就是限流，即拒绝部分访问请求，使访问负载压力降低到一个系统可以承受的程度。这样虽然有部分用户访问失败，但是整个系统依然是可用的，依然能对外提供服务，而不是因为负载压力太大而崩溃，导致所有用户都不能访问。
        为此，我们准备开发一个限流器，产品名称为“Diana”。
## 14.1 需求分析
    我们将 Diana 定位为一个限流器组件，即 Diana 的主要应用场景是部署在微服务网关或者其他 HTTP 服务器入口，以过滤器的方式对请求进行过滤，对超过限流规则的请求返回“服务不可用”HTTP 响应。
    Diana 的限流规则可通过配置文件获取，并需要支持本地配置和远程配置两种方式，远程配置优先于本地配置。限流方式包括：
         全局限流：针对所有请求进行限流，即保证整个系统处理的请求总数满足限流配置。
         账号限流：针对账号进行限流，即对单个账号发送的请求进行限流。
         设备限流：针对设备进行限流，即对单个客户端设备发送的请求进行限流。
         资源限流：针对某个资源（即某个 URL）进行限流，即保证访问该资源的请求总数满足限流配置。
    并且 Diana 设计应遵循开闭原则，能够支持灵活的限流规则功能扩展，即未来在不修改现有代码和兼容现有配置文件的情况下，支持新的配置规则。
### 14.2.2 高可用设计
   为了保证配置中心服务器和 Redis 服务器宕机时，限流器组件的高可用。限流器应具有自动降级功能，即配置中心不可用，则使用本地配置；Redis 服务器不可用，则降级为本地限流。
## 14.3 详细设计
    常用的限流算法有 4 种，
    固定窗口（Window）限流算法，滑动窗口（Sliding Window）限流算法，漏桶（Leaky Bucket）限流算法，令牌桶（Token Bucket）限流算法。

# 17. 如何让系统抗住双十一的预约抢购活动？
    我们先把需求梳理一下，总的来说，实现一个抢购系统大概可以分为四个阶段。
     商品预约：用户进入商品详情页面，获取购买资格，并等待商品抢购倒计时。
     等待抢购：等待商品抢购倒计时，直到商品开放抢购。
     商品抢购：商品抢购倒计时结束，用户提交抢购订单，排队等待抢购结果，抢购成功后，扣减系统库存，生成抢购订单。
     订单支付：等待用户支付成功后，系统更新订单状态，通知用户购买成功。
    接下来，我们就针对各阶段容易出现的问题，来分析其中的技术考点和解决方案
# 17.1 商品预约阶段
    那么问题来了：如何在高并发量的情况下，让每个用户都能得到抢购资格呢？这是预约抢购场景第一个技术考察点。 那你可以基于“06 | 分布式系统中，如何回答锁的实现原理？”来控制抢购资格的发放。
    我们基于 Redis 实现分布式锁（这是最常用的方式），在加锁的过程中，实际上是给Key 键设置一个值，为避免死锁，还要给
        SET lock_key unique_value NX PX 1000
     lock_key 就是 key 键；
     unique_value 是客户端生成的唯一的标识；
     NX 代表只在 lock_key 不存在时，才对 lock_key 进行设置操作；
     PX 10000 表示设置 lock_key 的过期时间为 10s，这是为了避免客户端发生异常而无法释放锁。
# 17.2 等待抢购阶段
    那么问题来了：如何解决等待抢购时间内的流量突增问题呢？有两个解决思路。
     页面静态化
     服务端限流
# 17.3 商品抢购阶段
    从“商品抢购阶段的架构设计”中我们可以总结出三个技术考点：流量削峰、扣减库存、分库分表。
# 17.4 订单支付阶段
    订单支付后操作（异常）
    所以你还要考虑“05 | 海量并发场景下，如何回答分布式事务一致性问题？”中，可靠消息投递机制：
    先做消息的本地存储，再通过异步重试机制，来实现消息的补偿。
    比如当支付平台回调订单系统，然后在更新状态的同时，插入一个消息，之后再返回第三方支付操作成功的结果。
    最后，通过数据库中的这条消息，再异步推送其他系统，完成后续的工作。
    mjj个人答疑解惑：(详见 SpringBoot订单支付后消息可靠补偿方案.md)
        SpringBoot订单支付后消息可靠补偿方案
        在订单支付后的操作中，发送异步消息到积分和短信服务时可能会遇到网络抖动、服务不可用等异常情况。下面提供一个完整的可靠消息补偿方案，包含本地消息表和异步重试机制。
            方案设计
            1. 本地消息表：在业务数据库中创建消息表，记录需要发送的消息
            2. 事务一致性：将业务操作和消息记录放在同一个事务中
            3. 定时任务：定期扫描未完成的消息进行重试
            4. 幂等处理：消费端需要实现幂等性，防止重复消费

# 18. 如果让你设计一个支持千万级流量的架构，你会怎么设计？
## 18.1 前端优化
    前端的优化主要有三个环节：减少请求次数、页面静态化、边缘计算。
        减少请求次数：减少前端脚本与后端服务的请求次数，有三种方案。
         增加缓存控制
         减少图像的请求次
         减少脚本的请求
## 18.2 后端优化
    后端环节的性能问题，可以从基础设施层面、网络层面、架构层面三个角度进行考量

# 19. 如何设计 RPC 框架在 10 万 QPS 下实现毫秒级的服务调用？
## 19.2 如何提升网络传输性能
    常见的五种 I/O 模型：
        同步阻塞 I/O；
        同步非阻塞 I/O；
        同步多路 I/O 复用；
        信号驱动 I/O；
        异步 I/O。
    你需要理解这五种 I/O 模型的区别和特点，不过在理解上你可能会有些难度，所以我来做个比喻方便你理解。
    我们把 I/O 过程比喻成烧水倒水的过程，等待资源（就是烧水的过程），使用资源（就是倒水的过程）：
        如果你站在灶台边上一直等着（等待资源）水烧开，然后倒水（使用资源），那么就是同步阻塞 I/O；
        如果你偷点儿懒，在烧水的时候躺在沙发上看会儿电视（不再时时刻刻等待资源），但是还是要时不时地去看看水开了没有，一旦水开了，马上去倒水（使用资源），那么这就是同步非阻塞 I/O；
        如果你想要洗澡，需要同时烧好多壶水，那你就在看电视的间隙去看看哪壶水开了（等待多个资源），哪一壶开了就先倒哪一壶，这样就加快了烧水的速度，这就是同步多路I/O 复用；
        不过你发现自己总是跑厨房去看水开了没，太累了，于是你考虑给你的水壶加一个报警器（信号），只要水开了就马上去倒水，这就是信号驱动 I/O；
        最后一种就高级了，你发明了一个智能水壶，在水烧好后自动就可以把水倒好，这就是异步 I/O。
    这五种 I/O 模型中最被广泛使用的是多路 I/O 复用，Linux 系统中的 select、epoll等系统调用都是支持多路 I/O 复用模型的，Java 中的高性能网络框架 Netty 默认也是使用这种模型。你可以选择它。
## 19.3 选择合适的序列化方式
    综合上面的几个考虑点，在我看来，我们的序列化备选方案主要有以下几种：
        首先是大家熟知的 JSON，它起源于 JavaScript 是一种最广泛使用的序列化协议，它的优势简单易用，同时在性能上相比 XML
        Thrift 是 Facebook 开源的高性能的序列化协议，也是一个轻量级的 RPC 框架；
        Protobuf 是谷歌开源的序列化协议。它们的共同特点是无论在空间上还是时间上都有着很高的性能，缺点就是由于 IDL 存在带来一些使用上的不方便
    那么你要如何选择这几种序列化协议呢？这里我给你几点建议：
    如果对于性能要求不高，在传输数据占用带宽不大的场景下可以使用 JSON 作为序列化协议；
    如果对于性能要求比较高，那么使用 Thrift 或者 Protobuf 都可以。而 Thrift 提供了配套的 RPC 框架，所以想要一体化的解决方案，你可以优先考虑 Thrift；
    在一些存储的场景下，比如说你的缓存中存储的数据占用空间较大，那么你可以考虑使用 Protobuf 替换 JSON

# 21. 如何根据应用场景选择合适的消息中间件？
    引入消息中间件的目的是让它来扛住海量流量，流量先进入到消息队列中，然后消费端下游系统可以慢慢消费消息中间件中的数据，这样能有效保护下游系统不被瞬时的流量击破。

    在进行具体的选型时，我们可以结合自己团队的实际情况。
     如果公司或团队的技术栈以 Golang 为主，建议选择 RabbitMQ，RabbitMQ 在性能上的缺陷可以通过搭建多套集群加以规避。
     如果公司或团队的技术栈以 Java 为主，我建议使用 Kafka 或 RocketMQ。RocketMQ 和 Kafka 都是性能优秀的中间件，在这两者之间进行选择时可以更多地关注功能特性。RocketMQ 提供了消息重试、消息过滤、消息轨迹、消息检索
        等功能特性，特别是 RocketMQ 的消息检索功能，因此 RocketMQ 很适合核心业务场景。而 kafka 更加擅长于日志、大数据计算、流式计算等场景。

# 22. 如何提升 RocketMQ 顺序消费性能
## 22.1 RocketMQ 顺序消费设计缺
    回顾上面 RocketMQ 实现顺序消费的核心关键词，我们发现其实就是加锁、加锁、加锁。没错，为了实现顺序消费，RocketMQ 需要进行三次加锁：
     进行队列负载平衡后，对新分配的队列，并不能立即进行消息拉取，必须先在Broker 端获取队列的锁；
     消费端在正式消费数据之前，需要锁定 MessageQueue 和 ProceeQueue。上述三把锁的控制，让并发度受到了队列数量的限制。在互联网、高并发编程领域，通常是“谈锁色变”，锁几乎成为了性能低下的代名词。试图减少锁的使用、缩小锁的范围几乎是性能优化的主要手段。

# 23. 使用分布式调度框架该考虑哪些问题？
    因为定时调度任务的调度频率直接决定了消息发送的实时性，随着需要调度的任务越来越多，大部分定时调度框架对秒级别的定时调度都不太友好。这时的调度通常都是分钟级的，但分钟级的调度会给任务带来较大的延迟，这是大部分业务无法容忍的，怎么办呢？

    ElasticJob 可以通过支持流式任务解决这个问题。具体的思路是：将任务配置为按照分钟级进行调度，例如每分钟执行一次调度。每次调度按照分页去查找数据，处理完一批数据，再查询下一批，如果查到待处理数据，就继续处理数据，直到没有待处理数据时，
    才结束本次业务处理。如果本次处理时间超过了一个调度周期，那么利用 ElasticJob 的任务错过补偿执行机制会再触发一次调度。

    在业务高峰期，这种方式基本上提供了准实时的处理效果。只有在业务量较少时，如果处理完一批数据后没有其他待处理的数据，这时新到的数据才会延迟 1 分钟执行。
    综合来看，通过支持流式任务，我们可以极大地提高数据的处理时效。

    具体实现看 个人工作总结 2025/05/13 - java ElasticJob支持流式任务

# 26. 如何解决高并发下的库存抢购超卖少买问题？
## 26.3 令牌库存
    具体是使用 Redis 中的 list 保存多张令牌来代表库存，一张令牌就是一个库存，用户抢库存时拿到令牌的用户可以继续支付
        1 //放入三个库存
        2 redis> lpush prod_1475_stock_queue_1 stock_1
        3 redis> lpush prod_1475_stock_queue_1 stock_2
        4 redis> lpush prod_1475_stock_queue_1 stock_3
        5
        6 //取出一个，超过 0.5 秒没有返回，那么抢库存失败
        7 redis> brpop prod_1475_stock_queue_1 0.5
    具体实现看 个人工作总结 2025/05/13 - 使用RedisTemplate的List实现库存令牌管理
## 26.4 多库存秒杀
## 26.5 自旋互斥超时锁
## 26.6 CAS 乐观锁：锁操作后置
    除此之外我再推荐一个实现方式：CAS 乐观锁。相对于自旋互斥锁来说，它在并发争抢库存线程少的时候效率会更好。通常，我们用锁的实现方式是先抢锁，然后，再对数据进行操作。这个方式需要先抢到锁才能继续，而抢锁是有性能损耗的，即使没有其他线程抢锁，这个消耗仍旧存在。
    CAS 乐观锁的核心实现为：记录或监控当前库存信息或版本号，对数据进行预操作。
## 26.7 Redis Lua 方式实现 Redis 锁
    与“事务+乐观锁”类似的实现方式还有一种，就是使用 Redis 的 Lua 脚本实现多步骤库存操作。因为 Lua 脚本内所有操作都是连续的，这个操作不会被其他操作打断，所以不存在锁争抢问题。

# 27. 为什么高并发下数据写入不推荐关系数据库？
    总结(deepseek)
    高并发下不推荐关系数据库的主要原因在于其索引结构、锁机制、ACID特性实现和主从架构等方面的设计限制了写入性能。B+Tree索引的随机IO、锁竞争、事务开销和单点写入等问题使得关系数据库难以应对极高并发的写入场景1310。
    对于电商供应链系统，没有放之四海而皆准的数据库解决方案。合理的策略是根据不同业务场景选择最适合的数据库技术，形成混合架构：
        核心事务：关系数据库（MySQL/PostgreSQL）+ Redis缓存
        商品信息：文档数据库（MongoDB）
        用户行为：搜索引擎（ElasticSearch）或时序数据库
        分析报表：列式存储（ClickHouse）或数据仓库
        推荐系统：图数据库（Neo4j）

# 31. 假设数据库成为了性能瓶颈点，动态数据查询如何提升效率
## 31.4 缓存分类
   在我们日常开发中，常见的缓存主要就是静态缓存、分布式缓存和热点本地缓存这三种。
       静态缓存在 Web 1.0 时期是非常著名的，它一般通过生成 Velocity 模板或者静态HTML 文件来实现静态缓存。
       分布式缓存的大名可谓是如雷贯耳了，我们平时耳熟能详的 Memcached、Redis 就是分布式缓存的典型例子。
       那么我们会在代码中使用一些本地缓存方案，如 HashMap，Guava Cache 或者是Ehcache 等，
## 31.5 缓存的不足
    首先，缓存比较适合于读多写少的业务场景，并且数据最好带有一定的热点属性。这是因为缓存毕竟会受限于存储介质不可能缓存所有数据，那么当数据有热点属性的时候才能保证一定的缓存命中率。
    其次，缓存会给整体系统带来复杂度，并且会有数据不一致的风险。当更新数据库成功，更新缓存失败的场景下，缓存中就会存在脏数据。
    再次，之前提到缓存通常使用内存作为存储介质，但是内存并不是无限的。因此，我们在使用缓存的时候要做数据存储量级的评估，对于可预见的需要消耗极大存储成本的数据，要慎用缓存方案。同时，缓存一定要设置过期时间，这样可以保证缓存中的会是热点数据。
    最后，缓存会给运维也带来一定的成本，运维需要对缓存组件有一定的了解，在排查问题的时候也多了一个组件需要考虑在内。

# 34. 线上的 API 接口响应比较慢，该如何快速排查和定位问题？
## 34.1 定位问题
### 34.1.1 慢查询日志
    通常情况下，为了定位 sql 的性能瓶颈，我们需要开启 mysql 的慢查询日志。把超过指定时间的 sql 语句，单独记录下来，方面以后分析和定位问题。
    开启慢查询日志需要重点关注三个参数：
         slow_query_log 慢查询开关
         slow_query_log_file 慢查询日志存放的路径
         long_query_time 超过多少秒才会记录日志
    通过 mysql 的 set 命令可以设置：
        1 set global slow_query_log='ON';
        2 set global slow_query_log_file='/usr/local/mysql/data/slow.log';
        3 set global long_query_time=2;
    设置完之后，如果某条 sql 的执行时间超过了 2 秒，会被自动记录到 slow.log 文件中。
    当然也可以直接修改配置文件 my.cnf
        1 [mysqld]
        2 slow_query_log = ON
        3 slow_query_log_file = /usr/local/mysql/data/slow.log
        4 long_query_time = 2
    但这种方式需要重启 mysql服务
### 34.1.2 监控
     Metrics - 监控指标
        系统性能指标，包括请求成功率、系统吞吐量、响应时长
        资源性能指标，衡量系统软硬件资源使用情况，配合系统性能指标，观察系统资源水位
     Logs - 日志
        施压引擎日志，观察施压引擎是否健康，压测脚本执行是否有报错
        采样日志，采样记录 API 的请求和响应详情，辅助排查压测过程中的一些出错请求的参数是否正常，并通过响应详情，查看完整的错误信息
     Traces - 分布式链路追踪
        用于性能问题诊断阶段，通过追踪请求在系统中的调用链路，定位报错 API 的报错系统和报错堆栈，快速定位性能问题点。
## 34.3 链路追踪
    有时候某个接口涉及的逻辑很多，比如：查数据库、查 redis、远程调用接口，发 mq消息，执行业务代码等等。
    该接口一次请求的链路很长，如果逐一排查，需要花费大量的时间，这时候，我们已经没法用传统的办法定位问题了。有没有办法解决这问题呢？
    用分布式链路跟踪系统：skywalking。通过 skywalking 定位性能问题
    在 skywalking 中可以通过 traceId（全局唯一的 id），串联一个接口请求的完整链路。
    可以看到整个接口的耗时，调用的远程服务的耗时，访问数据库或者 redis 的耗时等等，功能非常强大。
    之前没有这个功能的时候，为了定位线上接口性能问题，我们还需要在代码中加日志，手动打印出链路中各个环节的耗时情况，然后再逐一排查。
## 34.4 问题排查
### 34.4.1 个别接口响应慢
#### 34.4.1.1 链路追踪
    使用 SkyWalking，展示出每一个与网络有关的耗时。比如：读写数据库、读写 Redis、
    SpringCloud 调用、Dubbo 调用等。这样就能立马定位是哪次操作耗时了。
    同时，SkyWalking 可以记录每一个 SQL 语句，可以帮助定位
## 34.5 垃圾回收
### 34.5.1 什么情况下，GC 会对程序产生影响？
    不管 Minor GC 还是 FGC，都会造成一定程度的程序卡顿（即 Stop The World：GC线程开始工作，其他工作线程被挂起），即使采用 ParNew、CMS 或者 G1 这些更先进的垃圾回收算法，也只是在减少卡顿时间，而并不能完全消除卡顿。
    那到底什么情况下，GC 会对程序产生影响呢？根据严重程度从高到底，包括以下 4 种情况：
    1. FGC 过于频繁
        a. FGC 通常比较慢，少则几百毫秒，多则几秒，正常情况 FGC 每隔几个小时甚至几天才执行一次，对系统的影响还能接受。
        b. 一旦出现 FGC 频繁（比如几十分钟执行一次），是存在问题的，会导致工作线程频繁被停止，让系统看起来一直有卡顿现象，也会使得程序的整体性能变差。
    2. YGC 耗时过长
        执行频率高：通常几秒到几分钟就会发生一次
        a. 一般来说，YGC 的总耗时在几十或者上百毫秒是比较正常的，虽然会引起系统卡顿几毫秒或者几十毫秒，这种情况几乎对用户无感知，对程序的影响可以忽略不计。
        b. 如果 YGC 耗时达到了 1 秒甚至几秒（都快赶上 FGC 的耗时了），那卡顿时间就会增大，加上 YGC 本身比较频繁，就会导致比较多的服务超时问题。
    3. FGC 耗时过长
        a. FGC 耗时增加，卡顿时间也会随之增加，尤其对于高并发服务，可能导致 FGC期间比较多的超时问题，可用性降低，这种也需要关注。
    4. YGC 过于频繁
        a. 即使 YGC 不会引起服务超时，但是 YGC 过于频繁也会降低服务的整体性能，对于高并发服务也是需要关注的。
### 34.5.2 如何排查
    1. 公司的监控系统：大部分公司都会有，可全方位监控 JVM 的各项指标。
    2. JDK 自带工具：jmap、jstat
        a. 查看堆内存各区域的使用率以及 GC 情况：jstat -gcutil pid 1000 （重点关注结果中的 YGC、YGCT、FGC、FGCT、GCT）
        b. 查看堆内存中的存活对象，并按空间排序：jmap -histo pid | head -n20
        c. dump 堆内存文件：jmap -dump:format=b,file=heap pid

# 35. 百万级别数据的 Excel 如何快速导入到数据库中
    详见https://github.com/chasesunshine/mjj-test-new-technology/demo-mybatis-plus11/doc/Spring Boot 多线程导入百万级Excel数据到数据库.md
## 35.6 总结
    提升 Excel 导入速度的方法：
    1.使用更快的 Excel 读取框架(推荐使用阿里 EasyExcel)
    2.对于需要与数据库交互的校验、按照业务逻辑适当的使用缓存。用空间换时间
    3.使用 values(),(),() 拼接长 SQL 一次插入多行数据
    4.使用多线程插入数据，利用掉网络 IO 等待时间(推荐使用并行流，简单易用)
    5.避免在循环中打印无用的日志

# 38. 系统升级过程中如何实现数据的平滑迁移
## 38.1 如何平滑地迁移数据库中的数据
    你可能会认为：数据迁移无非是将数据从一个数据库拷贝到另一个数据库，可以通过MySQL 主从同步的方式做到准实时的数据拷贝；也可以通过 mysqldump 工具将源库的数据导出，再导入到新库，这有什么复杂的呢？
    其实，这两种方式只能支持单库到单库的迁移，无法支持单库到多库多表的场景。
### 38.1.1 “双写”方案
    1. 将新的库配置为源库的从库，用来同步数据；如果需要将数据同步到多库多表，那么可以使用一些第三方工具获取 Binlog 的增量日志（比如开源工具 Canal），在获取增量日志之后就可以按照分库分表的逻辑写入到新的库表中了。
    2. 同时，我们需要改造业务代码，在数据写入的时候，不仅要写入旧库，也要写入新库。当然，基于性能的考虑，我们可以异步地写入新库，只要保证旧库写入成功即可。但是，我们需要注意的是，需要将写入新库失败的数据记录在单独的日志中，
        这样方便后续对这些数据补写，保证新库和旧库的数据一致性。
    3. 然后，我们就可以开始校验数据了。由于数据库中数据量很大，做全量的数据校验不太现实。你可以抽取部分数据，具体数据量依据总体数据量而定，只要保证这些数据是一致的就可以。
    4. 如果一切顺利，我们就可以将读流量切换到新库了。由于担心一次切换全量读流量可能会对系统产生未知的影响，所以这里最好采用灰度的方式来切换，比如开始切换
        10% 的流量，如果没有问题再切换到 50% 的流量，最后再切换到 100%。
    5. 由于有双写的存在，所以在切换的过程中出现任何的问题，都可以将读写流量随时切换到旧库去，保障系统的性能。
    6. 在观察了几天发现数据的迁移没有问题之后，就可以将数据库的双写改造成只写新库，数据的迁移也就完成了。
### 38.1.2 级联同步方案
    我们会在自建机房准备一个备库，在云上环境上准备一个新库，通过级联同步的方式在自建机房留下一个可回滚的数据库，具体的步骤如下：
    1. 先将新库配置为旧库的从库，用作数据同步；
    2. 再将一个备库配置为新库的从库，用作数据的备份；
    3. 等到三个库的写入一致后，将数据库的读流量切换到新库；
    4. 然后暂停应用的写入，将业务的写入流量切换到新库（由于这里需要暂停应用的写入，所以需要安排在业务的低峰期）。

# 39. 如何确保你的消息只被消费一次？
## 39.1 消息为什么会丢失
    如果要保证消息只被消费一次，首先就要保证消息不会丢失。那么消息从被写入到消息队列，到被消费者消费完成，这个链路上会有哪些地方存在丢失消息的可能呢？其实，主要存在三个场景：
        消息从生产者写入到消息队列的过程。
        消息在消息队列中的存储场景。
        消息被消费者消费的过程。
### 39.1.1 在消息生产的过程中丢失消息
    在这个环节中主要有两种情况。
    首先，消息的生产者一般是我们的业务服务器，消息队列是独立部署在单独的服务器上的。两者之间的网络虽然是内网，但是也会存在抖动的可能，而一旦发生抖动，消息就有可能因为网络的错误而丢失。
    针对这种情况，我建议你采用的方案是消息重传：也就是当你发现发送超时后你就将消息重新发一次，但是你也不能无限制地重传消息。一般来说，如果不是消息队列发生故障，或者是到消息队列的网络断开了，重试 2～3 次就可以了
    不过，这种方案可能会造成消息的重复，从而导致在消费的时候会重复消费同样的消息。比方说，消息生产时由于消息队列处理慢或者网络的抖动，导致虽然最终写入消息队列成功，但在生产端却超时了，
    生产者重传这条消息就会形成重复的消息，那么针对上面的例子，直观显示在你面前的就会是你收到了两个现金红包。
    那么消息发送到了消息队列之后是否就万无一失了呢？当然不是，在消息队列中消息仍然有丢失的风险。
### 39.1.2 在消息队列中丢失消息
    我给你的建议是：
    1. 如果你需要确保消息一条都不能丢失，那么建议不要开启消息队列的同步刷盘，而是需要使用集群的方式来解决，可以配置当所有 ISR Follower 都接收到消息才返回成功。
    2. 如果对消息的丢失有一定的容忍度，那么建议不部署集群，即使以集群方式部署，也建议配置只发送给一个 Follower 就可以返回成功了。
    3. 我们的业务系统一般对于消息的丢失有一定的容忍度，比如说以上面的红包系统为例，如果红包消息丢失了，我们只要后续给没有发送红包的用户补发红包就好了。
### 39.1.3 在消费的过程中存在消息丢失的可能
    所以，在这里你需要注意的是，一定要等到消息接收和处理完成后才能更新消费进度，但是这也会造成消息重复的问题，比方说某一条消息在处理之后，消费者恰好宕机了，那么因为没有更新消费进度，所以当这个消费者重启之后，还会重复地消费这条消息。
## 39.2 如何保证消息只被消费一次
    想要完全的避免消息重复的发生是很难做到的，因为网络的抖动、机器的宕机和处理的异常都是比较难以避免的，在工业上并没有成熟的方法，因此我们会把要求放宽，只要
    保证即使消费到了重复的消息，从消费的最终结果来看和只消费一次是等同的就好了，也就是保证在消息的生产和消费的过程是“幂等”的。
### 39.2.1 什么是幂等
    幂等是一个数学上的概念，它的含义是多次执行同一个操作和执行一次操作，最终得到的结果是相同的
    说白了，你可以这么理解“幂等”：一件事儿无论做多少次都和做一次产生的结果是一样的，那么这件事儿就具有幂等性。
### 39.2.2 在生产、消费过程中增加消息幂等性的保证
    在消息生产过程中，在 Kafka0.11 版本和 Pulsar 中都支持“produceridempotency”的特性，翻译过来就是生产过程的幂等性，这种特性保证消息虽然可能在生产端产生重复，但是最终在消息队列存储时只会存储一份。
    它的做法是给每一个生产者一个唯一的 ID，并且为生产的每一条消息赋予一个唯一ID，消息队列的服务端会存储 < 生产者 ID，最后一条消息 ID> 的映射。当某一个生产者产生新的消息时，消息队列服务端会比对消息 ID 是否与存储的最后一条 ID 一致，
        如果一致，就认为是重复的消息，服务端会自动丢弃。
    而在消费端，幂等性的保证会稍微复杂一些，你可以从通用层和业务层两个层面来考虑。在通用层面，你可以在消息被生产的时候，使用发号器给它生成一个全局唯一的消息ID，消息被处理之后，把这个 ID 存储在数据库中，
        在处理下一条消息之前，先从数据库里面查询这个全局 ID 是否被消费过，如果被消费过就放弃消费
    你可以看到，无论是生产端的幂等性保证方式，还是消费端通用的幂等性保证方式，它们的共同特点都是为每一个消息生成一个唯一的 ID，然后在使用这个消息的时候，
        先比对这个 ID 是否已经存在，如果存在，则认为消息已经被使用过。所以这种方式是一种标准的实现幂等的方式
    不过这样会有一个问题：如果消息在处理之后，还没有来得及写入数据库，消费者宕机了重启之后发现数据库中并没有这条消息，还是会重复执行两次消费逻辑，这时你就需要引入事务机制，保证消息处理和写入数据库必须同时成功或者同时失败，
        但是这样消息处理的成本就更高了，所以，如果对于消息重复没有特别严格的要求，可以直接使用这种通用的方案，而不考虑引入事务
    在业务层面怎么处理呢？这里有很多种处理方式，其中有一种是增加乐观锁的方式。比如，你的消息处理程序需要给一个人的账号加钱，那么你可以通过乐观锁的方式来解决。具体的操作方式是这样的：你给每个人的账号数据中增加一个版本号的字段，
        在生产消息时先查询这个账户的版本号，并且将版本号连同消息一起发送给消息队列。消费端在拿到消息和版本号后，在执行更新账户金额 SQL 的时候带上版本号，类似于执行：
        update user set amount = amount + 20, version=version+1 where userId=1 and version=1;
    你看，我们在更新数据时给数据加了乐观锁，这样在消费第一条消息时，version 值为1，SQL 可以执行成功，并且同时把 version 值改为了 2；在执行第二条相同的消息时，由于 version 值不再是 1，所以这条 SQL 不能执行成功，也就保证了消息的幂等性。

# 40. 如何设计一个在生产环境下做全链路压测的平台
## 40.1 什么是压力测试
    不过，我想让你回想一下，自己是怎么做压力测试的？是不是像很多同学一样：先搭建一套与正式环境功能相同的测试环境，并且导入或者生成一批测试数据，然后在另一台服务器，启动多个线程并发地调用需要压测的接口（接口的参数一般也会设置成相同的，
        比如，想要压测获取商品信息的接口，那么压测时会使用同一个商品 ID）。最后，通过统计访问日志，或者查看测试环境的监控系统，来记录最终压测 QPS 是多少之后，直接交差？
    这么做压力测试其实是不正确的，错误之处主要有以下几点：
    1. 首先，做压力测试时，最好使用线上的数据和线上的环境，因为，你无法确定自己搭建的测试环境与正式环境的差异，是否会影响到压力测试的结果；
    2. 其次，压力测试时不能使用模拟的请求，而是要使用线上的流量。你可以通过拷贝流量的方式，把线上流量拷贝一份到压力测试环境。因为模拟流量的访问模型，和线上流量相差很大，会对压力测试的结果产生比较大的影响。
        比如，你在获取商品信息的时候，线上的流量会获取不同商品的数据，这些商品的数据有的命中了缓存，有的没有命中缓存。如果使用同一个商品 ID 来做压力测试，那么只有第一次请求没有命中缓存，
        而在请求之后会将数据库中的数据回种到缓存，后续的请求就一定会命中缓存了，这种压力测试的数据就不具备参考性了。
    3. 不要从一台服务器发起流量，这样很容易达到这台服务器性能瓶颈，从而导致压力测试的 QPS 上不去，最终影响压力测试的结果。而且，为了尽量真实地模拟用户请求，我们倾向于把流量产生的机器，放在离用户更近的位置，
        比如放在 CDN 节点上。如果没有这个条件，那么可以放在不同的机房中，这样可以尽量保证压力测试结果的真实性。
    之所以有很多同学出现这个问题，主要是对压力测试的概念没有完全理解，以为只要是使用多个线程并发的请求服务接口，就算是对接口进行压力测试了。
    那么究竟什么是压力测试呢？压力测试指的是，在高并发大流量下，进行的测试，测试人员可以通过观察系统在峰值负载下的表现，从而找到系统中存在的性能隐患。与监控一样，压力测试是一种常见的，发现系统中存在问题的方式，
        也是保障系统可用性和稳定性的重要手段。而在压力测试的过程中，我们不能只针对某一个核心模块来做压测，而需要将接入层、所有后端服务、数据库、缓存、消息队列、中间件以及依赖的第三方服务系统及其资源，都纳入压力测试的目标之中。
        因为，一旦用户的访问行为增加，包含上述组件服务的整个链路都会受到不确定的大流量的冲击，因此，它们都需要依赖压力测试来发现可能存在的性能瓶颈，这种针对整个调用链路执行的压力测试也称为“全链路压测”。
## 40.2 如何搭建全链路压测平台
    搭建全链路压测平台，主要有两个关键点。
    一点是流量的隔离。由于压力测试是在正式环境进行，所以需要区分压力测试流量和正式流量，这样可以针对压力测试的流量做单独的处理。
    另一点是风险的控制。也就是，尽量避免压力测试对于正常访问用户的影响，
    因此，一般来说全链路压测平台需要包含以下几个模块：
        流量构造和产生模块；
        压测数据隔离模块；
        系统健康度检查和压测流量干预模块。

# 41. [线上问题排查]MQ 消息队列消息堆积问题排查和解决思路
    MQ 执行有三大阶段：
         消息生产阶段。
         消息存储阶段。
         消息消费阶段。
    很显然，消息堆积是出现在第三个消息消费阶段的。
## 41.2 排查以及解决
### 41.2.1 方案一 增消费者
    第一我们想到的原因，流量激增，生成的订单速度远远大于消费者消费消息的速度，目前我们只部署了三个节点，那我们是否增加消费者，就可以解决这个问题，让消费者消费消息的速度远远大于生成者生成消息的速度，
        那消息就不存在堆积的问题，自然服务器压力也就下来了
    通知运维，再部署三个点，也是就增加三个消费者，由原来的三个消费者变为 6 个消费者，信心满满的部署完成后，等待一段时间，不出意外还是出了意外，消息还是在持续堆积，没有任何改善，我心里那个急啊，为什么增加了消费者？一点改善没有呢
### 41.2.2 方案二 优化消费者的处理逻辑
    消费者逻辑优化，屏蔽掉调用库存的接口，直接处理消息，但这种我们的逻辑是不完成，虽然能减少服务器的压力，后续处理起来也非常的麻烦，这种方式不可取
### 41.2.3 方案三 清空堆积的消息
    为了减少消息的堆积，减轻服务器的压力，我们是否可以把 mq 里面的消息拿出来，先存储，等服务恢复后，再把存储的消息推送到 mq，再处理呢？
    新建消费者，消费 rabbitmq 的消息，不做任何业务逻辑处理，直接快速消费消息，把消息存在一张表里，这样就没消息的堆积，服务器压力自然就下来了
    这方案上线后，过了一段时间观察，消息不再堆积，服务器的负载也下来了，我内心也不再慌了，那存储的那些消息，还处理吗？当然处理，怎么处理呢？
    后续等库存服务问题解决后，停掉新的消费者，新建一个生产者，再把表里的订单数据推送到 rabbitmq，进行业务逻辑的处理
## 41.3 消息堆积为什么会导致 cpu 飙升呢？
    RabbitMQ 是一种消息中间件，用于在应用程序之间传递消息。当消息堆积过多时，可能会导致 CPU
    1. 消息过多导致消息队列堆积：当消息的产生速度大于消费者的处理速度时，消息会积累在消息队列中。如果消息堆积过多，RabbitMQ 需要不断地进行消息的存储、检索和传递操作，这会导致 CPU 使用率升
    2. 消费者无法及时处理消息：消费者处理消息的速度不足以追赶消息的产生速度，导致消息不断积累在队列中。这可能是由于消费者出现瓶颈，无法处理足够多的消息，或者消费者的处理逻辑复杂，导致消费过程耗费过多的 CPU 资源
    3. 消息重试导致额外的 CPU 开销：当消息处理失败时，消费者可能会进行消息的重试操作，尝试再次处理消息。如果重试频率较高，会导致消息在队列中频繁流转、被重复消费，这会增加额外的 CPU 开销。
    4. 过多的连接以及网络 IO：当消息堆积过多时，可能会引发大量的连接请求和网络数据传输。这会增加网络 IO
## 41.4 通用的解决方案
     增加消费者：通过增加消费者的数量来提升消息的处理能力。增加消费者可以分担消息消费的负载，缓解消息队列的堆积问题。
     优化消费者的处理逻辑：检查消费者的代码是否存在性能瓶颈或是复杂的处理逻辑。可以通过优化算法、减少消费过程的计算量或是提高代码的效率来减少消费者的 CPU 开销。
     避免频繁的消息重试：当消息无法处理时，可以根据错误类型进行不同的处理方式，如将无法处理的消息转移到死信队列中或进行日志记录。避免频繁地对同一消息进行重试，以减少额外的 CPU 开销。
     调整 RabbitMQ 配置：可以调整 RabbitMQ 的参数来适应系统的需求，如增加内存、调整消息堆积的阈值和策略，调整网络连接等配置。
     扩展硬件资源：如果以上措施无法解决问题，可能需要考虑增加 RabbitMQ 的集群节点或者扩容服务器的硬件资源，以提升整个系统的处理能力。

# 42. [线上问题排查]如果 JVM 出现频繁 FullGC该如何解决
    我们知道 Full GC 的触发条件大致情况有以下几种情况：
        1. 程序执行了 System.gc() //建议 jvm 执行 fullgc，并不一定会执行
        2. 执行了 jmap -histo:live pid 命令 //这个会立即触发 fullgc
        3. 在执行 minor gc 的时候进行的一系列检查
            执行 Minor GC 的时候，JVM 会检查老年代中最大连续可用空间是否大于了当前新生代所有对象的总大小。
            如果大于，则直接执行 Minor GC（这个时候执行是没有风险的）。
            如果小于了，JVM 会检查是否开启了空间分配担保机制，如果没有开启则直接改为执行 Full GC。
            如果开启了，则 JVM 会检查老年代中最大连续可用空间是否大于了历次晋升到老年代中的平均大小，如果小于则执行改为执行 Full GC。
            如果大于则会执行 Minor GC，如果 Minor GC 执行失败则会执行 Full GC
        （马佳健个人理解：因为新生代中对象有可能全部都晋升到老年代，所以需要判断老年代中的连续最大空间是否大于新生代所有对象的总大小）
        4. 使用了大对象 //大对象会直接进入老年代
        5. 在程序中长期持有了对象的引用 //对象年龄达到指定阈值也会进入老年代对于我们的情况，可以初步排除 1，2 两种情况，最有可能是 4 和 5 这两种情况。为了进一步排查原因，我们在线上开启了 -XX:+HeapDumpBeforeFullGC
            注意：
            JVM 在执行 dump 操作的时候是会发生 stop the word 事件的，也就是说此时所有的用户线程都会暂停运行。
            为了在此期间也能对外正常提供服务，建议采用分布式部署，并采用合适的负载均衡算法

# 43. [线上问题排查]JVM OOM 问题如何排查和解决
    五种常见的 oom 错误
         java.lang.OutOfMemoryError: Java heap space
         java.lang.OutOfMemoryError: unable to create new native thread
         java.lang.OutOfMemoryError: Metaspace
         java.lang.OutOfMemoryError: Direct buffer memory
         java.lang.OutOfMemoryError: GC overhead limit
## 43.1 通用手段
### 43.1.1 发现
    通过以下手段可以做到感知应该出现了 oom.
    1. 日志监控
        通过监控日志中关键字 java.lang.OutOfMemoryError，就可以知道应用是否出现oom.对于文件的监控，可以使用 filebeat 或者 flume 等采集
    2. 配置-XX:+ExitOnOutOfMemoryError
        当 jvm 启用该参数时，如果出现了 oom，就会自动退出程序，咱们的健康检测自然能发现应用不存在了，从而能发出告警
    3. 使用 jstat 监控 jvm 内存使用率
        通过 jstat 工具可以查看 jvm 的内存使用情况，如果老年代使用率一直是 100%，并且期间还在一直不断 GC，这也是发生了 oom 的一种现象。jstat -gcutil $pid 1000 使用该命令即可实现每秒打印一次 jvm 的内存信息。
        O 列代表老年代内存使用比例，YGC 和 FGC 分别代表新生代 GC 次数和老年代 GC 次数。
### 43.1.2 止血
    当应用出现 oom 时，意味着应用无法申请到内存来分配对象，那么咱们的业务代码就会处于混沌状态，不清楚能进行到哪一步，不清楚状态是否完备，业务的请求可能在系统无限阻塞。这种情况对于用户体验的伤害会非常大。
    所以这里有一个简单的方法就是，配置-XX:+HeapDumpOnOutOfMemoryError 参数，当应用发生 oom 后，自动关停，借助 k8s 的健康检测实现自动重启能力再次拉起来新的容器。
        注意，这里需要实现业务系统能够实现故障转移或者请求幂等。这样才能保证用户请求不会出问题。
## 43.2 解决方案
    对于 unable to create new native thread 、Metaspace、Direct buffer memory 和 GC overhead limit exceeded,它们的原因相对简单，可以直接给出结论。
     unable to create new native thread : 无法创建更多的操作系统线程，以下 3 种情况:
         说明当前系统的线程数过多，超过了系统线程数的上限，减少当前应用创建的线程即可。
         没有 native 内存
     Metaspace：
         说明 Metaspace 不够用，修改 -XX:MaxMetaspaceSize 启动参数，调大永久代空间即可
     Direct buffer memory：
         Direct ByteBuffer 的默认大小为 64 MB，一旦使用超出限制，就会抛出Directbuffer memory 错误
     GC overhead limit exceeded：
         当 jvm 98%的时间都在 GC 时，就会出现该异常。这种情况需要增大堆或者结合下面的方法继续排查。
### 43.2.1 分析
    当应用发生 oom 后，最佳的分析载体就是 heap dump。通过添加-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/app.dump参数，可以实现当应用发生 oom 时，全自动导出 heap dump。
    有了 heap dump，我们就可以借助 Eclipse MAT 这款工具来分析 heapdump 了
### 43.2.2 规避
    oom 发生的原因有两种:
        1. 应用正常，但是堆设置过小，无法支持正常的对象分配
        2. 应用发生了内存泄漏，导致应该被清理的对象没有清理，无限增长通过分析 heap dump，我们基本可以区分出两种情况，
            第一种情况，对象的分布都正确，没有那种以下占用 30%*-，甚至 50%的对象。第二种情况就是某一种类型的对象，占据了大量的内存空间。
            第一种情况的解决方案就是：
                3. 增大堆内存
                4. 优化应用内存使用效率
            第二种情况，就需要针对性分析了，这里笔者给出常见的 oom 原因，大家在问题排查时，可以逐个排除，直到找到正确答案：
                5. ThreadLocal 未清理
                6. 出现了未指定分页的大数据量查询
                7. 定时任务中 list 忘记清空，每次都追加数据
                8. 监控系统中使用了不可控的字段作为 label,导致 label 无限增长

# 44. [线上问题排查]CPU 使用率较高排查和解决思路
## 44.1 问题发现
   本文整理自一个真实的案例，是楼主负责的业务，在一次大促之前的压测时发现了这个问题。
   在每次大促之前，我们的测试人员都会对网站进行压力测试，这个时候会查看服务的cpu、内存、load、rt、qps等指标。
   在一次压测过程中，测试人员发现我们的某一个接口，在qps上升到500以后，CPU使用率急剧升高。
## 44.2 问题定位
   遇到这种问题，首先是登录到服务器，看一下具体情况
### 44.2.1 定位进程
    登录服务器，执行top命令，查看CPU占用情况：
    $top
     PID USER      PR NI VIRT RES SHRS% CPU%  MEM TIME+COMMAND
     1893 admin     20 07127m2.6g 38mS  181.7 32.6 10:20.26 java
     top 命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。
     通过以上命令，我们可以看到，进程ID为1893的Java进程的CPU占用率达到了181%，基本可以定位到是我们的Java应用导致整个服务器的CPU占用率飙升。
### 44.2.2 定位线程
    我们知道，Java是单进程多线程的，那么，我们接下来看看PID=1893的这个Java进程中的各个线程的CPU使用情况，同样是用top命令：
    $top-Hp 1893
         PID USER   PR NI VIRT RES SHRS  %CPU  %MEM     TIME+COMMAND
         4519 admin 20 07127m2.6g  38mR  18.6  32.6      0:40.11 java
    通过top-Hp1893命令，我们可以发现，当前1893这个进程中，ID为4519的线程占用CPU最高。
### 44.2.3 定位代码
    通过top命令，我们目前已经定位到导致CPU使用率较高的具体线程，那么我么接下来就定位下到底是哪一行代码存在问题。
    首先，我们需要把4519这个线程转成16进制：
    $printf %x 4519
    11a7
    接下来，通过jstack命令，查看栈信息：
     1 $sudo-u admin jstack 1893 |grep-A 200 11a7
     2 "HSFBizProcessor-DEFAULT-8-thread-5" #500 daemon prio=10 os_prio=0 tid=0x00007f632314a800 nid=0x11a2 runnable [0x000000005442a000]
     3 java.lang.Thread.State: RUNNABLE
     4 atsun.misc.URLClassPath$Loader.findResource(URLClassPath.java:684)
     5 atsun.misc.URLClassPath.findResource(URLClassPath.java:188)
     6 atjava.net.URLClassLoader$2.run(URLClassLoader.java:569)
     7 atjava.net.URLClassLoader$2.run(URLClassLoader.java:567)
     8 atjava.security.AccessController.doPrivileged(Native Method)
     9 atjava.net.URLClassLoader.findResource(URLClassLoader.java:566)
     10 atjava.lang.ClassLoader.getResource(ClassLoader.java:1093)
     11 atjava.net.URLClassLoader.getResourceAsStream(URLClassLoader.java:232)
     12 at org.hibernate.validator.internal.xml.ValidationXmlParser.getInputStreamForPath(ValidationXmlParser.java:248)
     13 at org.hibernate.validator.internal.xml.ValidationXmlParser.getValidationConfig(ValidationXmlParser.java:191)
     14 at org.hibernate.validator.internal.xml.ValidationXmlParser.parseValidationXml(ValidationXmlParser.java:65)
     15 at org.hibernate.validator.internal.engine.ConfigurationImpl.parseValidationXml(ConfigurationImpl.java:287)
     16 at org.hibernate.validator.internal.engine.ConfigurationImpl.buildValidatorFactory(ConfigurationImpl.java:174)
     17 atjavax.validation.Validation.buildDefaultValidatorFactory(Validation.java:111)
     18 at com.test.common.util.BeanValidator.validate(BeanValidator.java:30)
    通过以上代码，我们可以清楚的看到，BeanValidator.java的第30行是有可能存在问题的。
## 44.3 问题解决
   接下来就是通过查看代码来解决问题了，我们发现，我们自定义了一个BeanValidator，封装了Hibernate的Validator，然后在validate方法中，
    通过Validation.buildDefaultValidatorFactory().getValidator()初始化一个 Validator 实例，通过分析发现这个实例化的过程比较耗时。
   我们重构了一下代码，把Validator实例的初始化提到方法外，在类初始化的时候创建一次就解决了问题。
## 44.4 总结
   以上，展示了一次比较完成的线上问题定位过程。主要用到的命令有:top 、printf 和jstack
   另外，线上问题排查还可以使用Alibaba开源的工具Arthas进行排查，以上问题，可以使用一下命令定位：thread-n 3 //查看cpu占比前三的线程
   以上，本文介绍了如何排查线上服务器CPU使用率过高的问题，如果大家感兴趣，后面可以再介绍一些关于LOAD飙高、频繁GC等问题的排查手段。

# 45. [合集]海量数据下的数据统计高频面试题系列
## 45.1 [百度二面]内存100M下统计不同号码的个数
    已知某个文件内包含大量电话号码，每个号码为8位数字，如何统计不同号码的个数？内存限制100M
    个人做法：
        1. 如果号码数量在200万以内：使用HashSet最简单直接
        2. 如果号码数量巨大但可接受近似结果：使用布隆过滤器 BloomFilter
        3. 如果数据量极大且需要精确结果：使用外部排序方法
        4. 如果号码是数字且有固定模式：考虑位图法 BitSet
##  45.2 [美团一面]出现频率最高的100个词
    假如有一个1G大小的文件，文件里每一行是一个词，每个词的大小不超过16byte，要求返回出现频率最高的100个词。内存大小限制是10M
        第一步：分割大文件为多个小文件并分别统计词频
        第二步：合并所有小文件的统计结果
        第三步：使用PriorityQueue最小堆找出Top K
## 45.3 [字节一面]查找两个大文件共同的URL
    给定 a、b 两个文件，各存放 50 亿个 URL，每个 URL 各占 64B，找出 a、b两个文件共同的 URL。内存限制是 4G
    解决方案：分治+哈希
    步骤1：文件分片
        使用哈希函数将URL分配到不同的小文件中：
        对每个URL计算哈希值，如hash(URL) % 1000
        根据哈希值将URL分配到a0-a999和b0-b999的小文件中
        这样相同的URL会被分配到相同编号的小文件中
    步骤2：逐对处理小文件
        对于每一对相同编号的小文件(ai, bi)：
        将ai的URL加载到HashSet中（内存中可以容纳）
        遍历bi中的URL，检查是否存在于ai的HashSet中
        输出共同的URL
## 45.6 [大众点评]如何找出排名前 500 的数？
    有 1w 个数组，每个数组有 500 个元素，并且有序排列。如何在这 10000*500个数中找出前 500 的数？
    马佳健个人思路：
        1. 新建一个 PriorityQueue<Map.Entry<String, Integer>> minHeap = new PriorityQueue<>(Comparator.comparingInt(Map.Entry::getValue));
            这么一个优先级队列，按照值的大小进行排序
        2. 遍历这 1w 个数组
            遍历每个数组，放入 minHeap 中，它会按照值进行放入和排序，如果超过500个数，就一直offer，一直poll出去，直到遍历完成（以下是思路）
            minHeap.offer(entry);
            // 这地方是一旦超过了 k ，就在队列中把最小的给弹出
            if (minHeap.size() > k) {
                minHeap.poll();
            }

# 46. [线上问题排查]数据库出现死锁如何排查
    所以，面对线上偶发的 MySQL 死锁问题，我的排查处理过程如下：
    1. 线上错误日志报警发现死锁异常
    2. 查看错误日志的堆栈信息
    3. 查看 MySQL 死锁相关的日志
    4. 根据 binlog 查看死锁相关事务的执行内容
    5. 根据上述信息找出两个相互死锁的事务执行的 SQL 操作，根据本系列介绍的锁相关理论知识，进行分析推断死锁原因
    6. 修改业务代码
## 45.1 死锁日志的获取
    发生死锁异常后，我们可以直接使用 showengineinnodbstatus 命令获取死锁信息，但是该命令只能获取最近一次的死锁信息。所以，我们可以通过开启 InnoDB 的
        监控机制来获取实时的死锁信息，它会周期性（每隔 15 秒）打印 InnoDb 的运行状态到 mysqld 服务的错误日志文件中。
    InnoDb 的监控较为重要的有标准监控（StandardInnoDBMonitor）和 锁监控（InnoDB Lock Monitor），通过对应的系统参数可以将其开启。
        1-- 开启标准监控
        2 set GLOBAL innodb_status_output=ON;
        3-- 关闭标准监控
        4 set GLOBAL innodb_status_output=OFF;
        5-- 开启锁监控
        6 set GLOBAL innodb_status_output_locks=ON;
        7-- 关闭锁监控
        8 set GLOBAL innodb_status_output_locks=OFF;
    另外，MySQL 提供了一个系统参数 innodb_print_all_deadlocks 专门用于记录死锁日志，当发生死锁时，死锁日志会记录到 MySQL 的错误日志文件中。
         set GLOBAL innodb_print_all_deadlocks=ON;
## 45.3 binlog 的获取和分析
    binlog 日志会完整记录事务执行的所有 SQL，借助它，我们就能找到最终获取锁事务所执行的全部 SQL。然后再进行具体的锁冲突分析。
    我们可以使用 MySQL 的命令行工具Mysqlbinlog 远程获取线上数据库的 binlog日志。具体命令如下所示：
        cmd命令窗口：
            mysqlbinlog -h 127.0.0.1 -u root -p --read-from-remote-server binlog.0000056 --base64-output=decode-rows -v

# 47. 请你详细介绍一下扫码登录的实现原理？
    下面分阶段来看看设计原理。
    1、待扫描阶段
        首先是待扫描阶段，这个阶段是 PC 端跟服务端的交互过程。每次用户打开PC端登陆请求，系统返回一个唯一的二维码ID，并将二维码ID的信息绘制成二维码返回给用户。
        这里的二维码ID一定是唯一的，后续流程会将二维码ID跟身份信息绑定，不唯一的话就会造成你登陆了其他用户的账号或者其他用户登陆你的账号。此时在 PC 端会启动一个定时器，轮询查询二维码是否被扫描。如果移动端未扫描的话，那么一段时间后二维码将会失效。
    2、已扫描待确认阶段
        第二个阶段是已扫描待确认阶段，主要是移动端跟服务端交互的过程。
        首先移动端扫描二维码，获取二维码 ID，然后将手机端登录的凭证（token）和 二维码 ID 作为参数发送给服务端
        此时的手机在之前已经是登录的，不存在没登录的情况。
        服务端接受请求后，会将 token 与二维码 ID 关联，然后会生成一个临时token，这个 token 会返回给移动端，临时 token 用作确认登录的凭证。
        PC 端的定时器，会轮询到二维码的状态已经发生变化，会将 PC 端的二维码更新为已扫描，请在手机端确认。
    3、已确认
        扫码登录的最后阶段，用户点击确认登录，移动端携带上一步骤中获取的临时 token访问服务端。
        服务端校对完成后，会更新二维码状态，并且给 PC 端生成一个正式的 token。
        后续 PC 端就是持有这个 token 访问服务端。

# 49. [京东一面]如何用 Redis 统计用户访问量
    拼多多有数亿的用户，那么对于某个网页，怎么使用Redis来统计一个网站的用户访问数呢？
    1、Hash
        哈希是Redis的一种基础数据结构，Redis底层维护的是一个开散列，会把不同的key映射到哈希表上，如果是遇到关键字冲突，那么就会拉出一个链表出来
        当一个用户访问的时候，如果用户登陆过，那么我们就使用用户的id，如果用户没有登陆过，那么我们也能够前端页面随机生成一个key用来标识用户
        当用户访问的时候，我们可以使用HSET命令，key可以选择URI与对应的日期进行拼凑，field 可以使用用户的id或者随机标识，value可以简单设置为1。
        当我们要统计某一个网站某一天的访问量的时候，就可以直接使用HLEN来得到最终的结果了。
            [root@VM 0 2 centos ~]# redis-c
            redis-check-aof redis-check-rdbredis-cli
            [root@VM 0 2 centos ~]# redis-cli
            127.0.0.1:6379>hset index.html0527 11110 1
            (integer)1
            127.0.0.1:6379> hset index.html0527 11115 2
            (integer)1
            127.0.0.1:6379> hlen index.html0527
            (integer)2
        优点：简单，容易实现，查询也是非常方便，数据准确性非常高。
        缺点：占用内存过大。随着key的增多，性能也会下降。网站访问量不高还行，拼多多这种数亿PV的网站肯定顶不住。
    2、Bitset
        我们知道，对于一个32位的int，如果我们只用来记录id，那么只能够记录一个用户，但如果我们转成2进制，每位用来表示一个用户，那么我们就能够一口气表示32个用户，空间节省了32倍！
        对于有大量数据的场景，如果我们使用bitset，那么可以节省非常多的内存。
        对于没有登陆的用户，我们也可以使用哈希算法，把对应的用户标识哈希成一个数字id。bitset 非常的节省内存，假设有1亿个用户，也只需要100000000/8/1024/1024约等于12兆内存。
        Redis 已经为我们提供了SETBIT的方法，使用起来非常的方便，我们可以看看下面的例子。
        我们在item页面可以不停地使用SETBIT命令，设置用户已经访问了该页面，也可以使用GETBIT的方法查询某个用户是否访问。最后我们通过BITCOUNT可以统计该网页每天的访问数量。
            127.0.0.1:6379> setbit item.html0528 11111 1
            (integer)0
            127.0.0.1:6379>setbit item.html0528 11 1
            (integer)0
            127.0 0.1:6379> getbit item.html0528 33
            (integer)0
            127.0.0 1:6379> getbit item.html0528 11
            (integer)1
            127.0.0.1:6379> bitcount item.html0528
            (integer)2
        优点： 占用内存更小，查询方便，可以指定查询某个用户，数据可能略有瑕疵，对于非登陆的用户，可能不同的key映射到同一个id，否则需要维护一个非登陆用户的映射，有额外的开销。
        缺点： 如果用户非常的稀疏，那么占用的内存可能比方法一更大
        个人理解：
             redisTemplate.opsForValue().setBit("", 1, true)
             源码：               Boolean setBit(K key, long offset, boolean value);
             deepseek：
                 # RedisTemplate API 中的 setBit 方法含义
                 `Boolean setBit(K key, long offset, boolean value)` 是 Spring Data Redis 中 RedisTemplate 提供的一个方法，用于操作 Redis 的位图(bitmap)数据结构。
                 ## 方法参数解释
                     - `K key`: Redis 中位图的键名
                     - `long offset`: 位偏移量(从0开始)
                     - `boolean value`: 要设置的值(true表示1，false表示0)
                 ## 功能说明
                     这个方法用于对指定键的位图在指定偏移量处设置位值：
                     - 如果value为true，则将偏移量处的位设置为1
                     - 如果value为false，则将偏移量处的位设置为0
                 ## 返回值
                     该方法返回一个Boolean值，表示该偏移量处原来的位值：
                     - 返回true表示原来该位是1
                     - 返回false表示原来该位是0
                 ## 底层原理
                     这个方法对应于Redis的`SETBIT`命令，允许你对字符串值进行位级操作。Redis将字符串视为位数组，可以单独设置或获取每一位的值。
                 ## 使用示例
                     ```java
                     // 设置键"mybitmap"的第10位为1，并获取原来的值
                     Boolean previousValue = redisTemplate.opsForValue().setBit("mybitmap", 10, true);
                     // 设置键"flags"的第5位为0
                     redisTemplate.opsForValue().setBit("flags", 5, false);
                     ```
                 ## 注意事项
                     1. 如果键不存在，Redis会自动创建一个新的位图
                     2. 偏移量必须是非负整数
                     3. 位图会自动扩展以容纳设置的偏移量，中间未设置的位默认为0
                 位图常用于实现布隆过滤器、用户在线状态统计等场景。
    3、概率算法
        对于拼多多这种多个页面都可能非常多访问量的网站，如果所需要的数量不用那么准确，可以使用概率算法。
        事实上，我们对一个网站的UV的统计，1亿跟1亿零30万其实是差不多的。
        在Redis中，已经封装了HyperLogLog算法，他是一种基数评估算法。这种算法的特征，一般都是数据不存具体的值，而是存用来计算概率的一些相关数据。
            127.0.0.1:6379> pfadd pay.html0528 111 222 123 asb
            (integer)1
            127.0.0.1:6379> pfcount pay.html0528
            (integer)4
        当用户访问网站的时候，我们可以使用PFADD命令，设置对应的命令，最后我们只要通过PFCOUNT就能顺利计算出最终的结果，因为这个只是一个概率算法，所以可能存在0.81%的误差
        优点： 占用内存极小，对于一个key，只需要12kb。对于拼多多这种超多用户的特别适用。
        缺点： 查询指定用户的时候，可能会出错，毕竟存的不是具体的数据。总数也存在一定的误差。
        上面就是常见的3种适用Redis统计网站用户访问数的方法了。
            deepseek：
                # Redis PFADD 命令解析
                    您提供的命令是 Redis 的 HyperLogLog 数据结构操作命令：
                    ```
                    PFADD pay.html0528 111 222 123 asb
                    ```
                ## 命令含义
                    `PFADD` 是 Redis HyperLogLog 数据结构的添加命令，用于:
                    1. 向名为 `pay.html0528` 的 HyperLogLog 结构中添加元素 `111`, `222`, `123`, `asb`
                    2. 如果 HyperLogLog 不存在，会自动创建
                    3. 如果添加的元素导致基数估计发生变化，返回 1；否则返回 0
                ## HyperLogLog 特性
                    1. **高效统计不重复元素**：用于估计集合的基数(唯一元素数量)
                    2. **固定内存占用**：无论添加多少元素，只占用约12KB内存
                    3. **误差率约0.81%**：是概率性数据结构，不是精确计数
                ## 使用场景
                    - 统计网站每日独立访客(UV)
                    - 统计搜索关键词的不同数量
                    - 统计用户点击的不同商品ID数量
                ## 相关命令
                    - `PFCOUNT key`：获取基数估计值
                    - `PFMERGE destkey sourcekey [sourcekey...]`：合并多个HyperLogLog
                ## 注意事项
                    1. HyperLogLog 只提供基数估计，不存储实际元素
                    2. 无法获取已添加的元素列表
                    3. 适合大数据量下的近似统计，不适用于需要精确结果的场景
                您可以使用 `PFCOUNT pay.html0528` 来查看这个 HyperLogLog 中估计的唯一元素数量。

# 50. shoppe面试题实时订阅推送设计与实现
    什么是订阅推送？就是用户订阅了优惠劵的推送，在可领取前的一分钟就要把提醒信息推送到用户的app中。具体方案就是到具体的推送时间点了，coupon系统调用消息中心的推送接口，把信息推送出去。
    下面我们分析一下这个功能的业务情景。假设公司目前注册用户6000W+，比如有一张无门槛的优惠劵下单立减20元，那么抢这张劵的人就会比较多，我们保守估计10W+，百万级别不好说。
        我们初定为20W万人，那么这20W条推送信息要在一分钟推送完成！并且一个用户是可以订阅多张劵的。所以我们知道了这个订阅功能的有两个突出的难点：
        1、推送的实效性：推送慢了，用户会抱怨没有及时通知他们错过了开抢时机。
        2、推送的体量大：爆款的神劵，人人都想抢！
    推送的实效性的问题：当用户在领劵中心订阅了某个劵的领取提醒后，在后台就会生成一条用户的订阅提醒记录，里面记录了在哪个时间点给用户发送推送信息。所以问题就变成了系统如何快速实时选出哪些要推送的记录！
         方案1：MQ的延迟投递。MQ虽然支持消息的延迟投递，但是不适合用来做精确时间点投递！并且用户执行订阅之后又取消订阅的话，要把发出去的MQ消息
                delete 掉这个操作有点头大，短时间内难以落地！并且用户可以取消之后再订阅，这又涉及到去重的问题。所以MQ的方案否掉。
         方案2：传统定时任务。这个相对来说就简单一点，用定时任务是去db里面load用户的订阅提醒记录，从中选出当前可以推送的记录。但有句话说得好任何脱离实
                际业务的设计都是耍流氓。下面我们就分析一下传统的定时任务到底适不适合我们的这个业务!
                    能否支持多机同时跑       一般不能，同一时刻只能单机跑。
                    存储数据源              一般是mysql或者其它传统数据库，并且是单
                    频率                   支持秒、分、时、天，一般不能太快
                    如上表格所示，可以看到一般传统的定时任务存在以下缺点：
                    1、性能瓶颈。只有一台机在处理，在大体量数据面前力不从心！
                    2、实效性差。定时任务的频率不能太高，太高会业务数据库造成很大的压力！
                    3、单点故障。万一跑的那台机挂了，那整个业务不可用了。这是一个很可怕的事情！
                    所以传统定时任务也不太适合这个业务。
                    那有其他解决方案吗？其实可以对传统的定时任务做一个简单的改造即可！把它变成可以同时多机跑，并且实效性可以精确到秒级，并且拒绝单点故障的定时任务集群！这其中就要借助我们的强大的redis了。
         方案3：定时任务集群
            首先我们要定义定时任务集群要解决的三个问题！
            1、实效性要高
            2、吞吐量要大
            3、服务要稳定，不能有单点故障
            架构很简单：我们把用户的订阅推送记录存储到redis集群的sortedSet队列里面，且以提醒用户提醒时间戳作为score值，然后在我们个每业务server里面起一个定时器频率是秒级，我的设定就是1s，
            然后经过负载均衡之后从某个队列里面获取要推送的用户记录进行推送。下面我们分析以下这个架构。
                1、性能：除去带宽等其它因素，基本与机器数成线性相关。机器数量越多吞吐量越大，机器数量少时相对的吞吐量就减少。
                2、实效性：提高到了秒级，效果还可以接受。
                3、单点故障？不存在的！除非redis集群或者所有server全挂了。
            这里解释一下为什么用redis？
                1. redis 可以作为一个高性能的存储db，性能要比MySQL好很多，并且支持持久化，稳定性好。
                2. redis SortedSet 队列天然支持以时间作为条件排序，完美满足我们选出要推送的记录。
            既然方案已经有了，怎么实现呢？
            首先我们以user_id作为key，然后mod队列数hash到redisSortedSet队列里面。为什么要这样呢，因为如果用户同时订阅了两张劵并且推送时间很近，这样的两条推送就可以合并成一条，并且这样hash也相对均匀。
                Long add = redisManager.zadd(getSubscribeQueue(userId), grantTime.getTime(), subscribeContent);
                    getSubscribeQueue(userId) - 这是有序集合的键(key)，通常是一个字符串，表示这个有序集合的名称。这里通过一个方法根据用户ID生成特定的队列名称。
                    grantTime.getTime() - 这是成员的分数(score)，一个双精度浮点数。在这里使用的是时间戳（通过getTime()方法获取的毫秒数），Redis 会根据这个分数对集合中的成员进行排序。
                    subscribeContent - 这是要添加到有序集合中的成员(member)，可以是字符串或其他数据类型，但需要能序列化为字符串。

# 51. [阿里一面]购物车系统怎么设计？
## 1 主要功能
    在用户选购商品时，下单前，暂存用户想购买的商品。
    购物车对数据可靠性要求不高，性能也无特别要求，在整个电商系统是相对容易设计和实现的一个子系统。
    购物车系统的主要功能：
         把商品加入购物车（后文称“加购”）
         购物车列表页
         发起结算下单
         在所有界面都要显示的购物车小图标
    支撑这些功能，存储模型如何设计？
    只要一个“购物车”实体
## 2 主要属性
    打开京东购物车页面：SKUID（商品ID）、数量、加购时间和勾选状态
    “勾选状态”属性，即在购物车界面，每件商品前面的那个小对号，表示在结算下单时，是否要包含这件商品。至于商品价格和总价、商品介绍等都能实时从其他系统获取，无需购物车系统保存。
    购物车功能简单，但设计购物车系统的存储时，仍有一些问题需考虑
## 3 原则
### 3.1 思考
#### 3.1.1 用户未登录，在浏览器中加购，关闭浏览器再打开，刚才加购的商品还在吗？
    存在。
    若用户未登录，加购的商品也会被保存在用户的电脑。即使关闭浏览器再打开，购物车的商品仍存在。
#### 3.1.2 用户未登录，在浏览器中加购，然后登录，刚才加购的商品还在吗？
    存在。
    若用户先加购，再登录。登录前加购的商品就会被自动合并到用户名下，所以登录后购物车中仍有登录前加购的商品。
#### 3.1.3 关闭浏览器再打开，上一步加购的商品还在吗？
    不存在。
    关闭浏览器再打开，这时又变为未登录状态，但是之前未登录时加购的商品已经被合并到刚刚登录的用户名下了，所以购物车是空的。
#### 3.1.4 再打开手机，用相同的用户登录，第二步加购的商品还在吗？
    存在。使用手机登录相同的用户，看到的就是该用户的购物车，这时无论你在手机App、电脑还是微信中登录，只要相同用户，看到就是同一购物车，所以第2步加购的商品是存在的。
    若不仔细把这些问题考虑清楚，用户使用购物车时，就会感觉不好用，不是加购的商品莫名其妙丢了，就是购物车莫名其妙多出一些商品。要解决上面这些问题，只要在存储设计时，把握如下
## 3.2 原则
    • 若未登录，需临时暂存购物车的商品
    • 用户登录时，把暂存购物车的商品合并到用户购物车，并清除暂存购物车
    • 用户登录后，购物车中的商品，需在浏览器、手机APP和微信等等这些终端保持同步
   购物车系统需保存两类购物车：
    • 未登录情况下的“暂存购物车”
    • 登录后的“用户购物车”
## 4 “暂存购物车”存储设计
### 4.1 保存在客户端or服务端？
    若存在服务端，则每个暂存购物车都得有个全局唯一标识，这不易设计。保存在服务端，还要浪费服务端资源。所以，肯定保存在客户端：
         • 节约服务器存储资源
         • 无购物车标识问题每个客户端就保存它自己唯一一个购物车即可，无需标识。
    客户端存储可选择不多：
         •Session不太合适。SESSION保留时间短，且SESSION的数据实际上还是保存在服务端
         •Cookie
         •LocalStorage浏览器的LocalStorage和App的本地存储类似，都以LocalStorage 代表。Cookie、LocalStorage 都可用来保存购物车数据。
    选择哪种更好？各有优劣。这场景中，使用Cookie和LocalStorage最关键区别：
         • 客户端、服务端的每次交互，都会自动带着Cookie数据往返，这样服务端可读写客户端Cookie中的数据
         •LocalStorage里的数据，只能由客户端访问
    使用Cookie存储，实现简单，加减购物车、合并购物车过程，由于服务端可读写Cookie，这样全部逻辑都可在服务端实现，并且客户端和服务端请求的次数也相对少。
    使用LocalStorage 存储，实现相对复杂，客户端和服务端都要实现业务逻辑，但LocalStorage 好在其存储容量比Cookie的4KB上限大得多，而且不用像Cookie那样，无论用不用，每次请求都要带着，可节省带宽
    所以，选择Cookie或LocalStorage存储“暂存购物车”都行，根据优劣势选型即可：
         • 设计的是个小型电商，Cookie存储实现起来更简单
         • 你的电商是面那种批发的行业用户，用户需加购大量商品，Cookie可能容量不够用，选择LocalStorage更合适
## 5 用户购物车 存储设计
    用户购物车须保证多端数据同步，数据须保存在服务端。常规思路：设计一张购物车表，
    把数据存在MySQL。表结构同样参照实体模型：
        列名               数据类型               主键          非空              说明
        id                  BIGINT              是            是              自增主键
        user id             BIGINT                            是              用户ID
        sku id              BIGINT                            是              商品ID
        count               INT                               是              商品数量
        timestamp           DATE                              是              加购时间
        selected            TINyINT (1)                                      购选状态
    需在user_id 建索引，因为查询购物车表，都以user_id作为查询条件。
    也可选择更快的Redis保存购物车数据：
         • 用户ID=Key
         •Redis的HASH=Value，保存购物车中的商品
    如：
        {
        	"KEY": 6666,
        	"VALUE": [{
        			"FIELD": 8888,
        			"FIELD_VALUE": {
        				"timestamp": 1578721136,
        				"count": 1,
        				"selected": true
        			}
        		},
        		{
        			"FIELD": 6666,
        			"FIELD_VALUE": {
        				"timestamp": 1578721138,
        				"count": 2,
        				"selected": false
        			}
        		}
        	]
        }
    为便理解，用JSON表示Redis中HASH的数据结构:
      •KEY中的值6666是用户ID
      •FIELD存放商品ID
      •FIELD_VALUE是个JSON字符串，保存加购时间、商品数量和勾选状态
    读写性能，Redis比MySQL快得多，Redis就一定比MySQL好吗？
### 5.1 MySQL V.S Redis 存储
     •Redis性能比MySQL高出至少一个量级，响应时间更短，支撑更多并发请求
     •MySQL数据可靠性好于Redis，因为Redis异步刷盘，若服务器掉电，Redis有可能丢数据。但考虑到购物车里的数据，对可靠性要求不高，丢少量数据的后果也就是，个别用户的购物车少了几件商品，问题不大。
        所以，购物车场景，Redis数据可靠性不高这个缺点，不是不能接受
     •MySQL另一优势：支持丰富的查询方式和事务机制，但对购物车核心功能无用。但每个电商系统都有它个性化需求，若需以其他方式访问购物车数据，如统计今天加购的商品总数，这时，使用MySQL存储数据，易实现，而使用Redis存储，查询麻烦且低效
    综合比较下来，考虑到需求变化，推荐MySQL存储购物车数据。若追求性能或高并发，也可选择使用Redis。
    比如，一般认为数据绝不可丢，即不能牺牲数据可靠性。但用户购物车存储，使用Redis替代MySQL，就是牺牲数据可靠性换取高性能。很低概率的丢失少量数据可接受。性能提升带来的收益远大于丢失少量数据而付出的代价，这选择就值得。
        如果说不考虑需求变化这个因素，牺牲一点点数据可靠性，换取大幅性能提升，Redis是最优解。
## 6 总结
     • 购物车系统的主要功能包括：加购、购物车列表页和结算下单
     • 核心实体：只有一个“购物车”实体
     • 至少包括：SKUID、数量、加购时间和勾选状态属性在给购物车设计存储时，为确保：
     • 购物车内的数据在多端一致
     • 用户登录前后购物车内商品能无缝衔接
        除了每个用户的“用户购物车”，还要实现一个“暂存购物车”保存用户未登录时加购的商品，并在用户登录后自动合并“暂存购物车”和“用户购物车”。暂存购物车存储在客户端浏览器或App，可存放到Cookie或LocalStorage。
        用户购物车保存在服务端，可以选择使用：
     •Redis存储会有更高的性能，可以支撑更多的并发请求
     •MySQL是更常规通用的方式，便于应对变化，系统扩展性更好
## 思考
    既然用户的购物车数据存放在MySQL或Redis各有优劣。那能否把购物车数据存在MySQL，并用Redis缓存？不就兼顾二者优势？若可行，如何保证Redis中的数据和MySQL数据一致性？
    用Redis给购物车库做缓存，技术可行。但考虑：
     值得吗？每个人的购物车都不一样，所以这个缓存它的读写比差距不会很大，缓存命中率不会太高，缓存收益有限，为维护缓存，还会增加系统复杂度。所以我们就要自行权衡一下，是不是值得的问题。除非超大规模系统，否则没必要设置这缓存
     若非要做这样一个缓存，用什么缓存更新策略？

# 52. [合集]2025年一线大厂面试真题
## 46.1 [美团]CMS的垃圾回收过程。为啥要分成4步
    # CMS垃圾回收器的四步回收过程
        CMS (Concurrent Mark-Sweep) 垃圾回收器是HotSpot JVM中的一种以获取最短回收停顿时间为目标的收集器，它的回收过程分为四个主要步骤。这种分步设计是为了实现并发标记和减少停顿时间。
    ## CMS的四个回收步骤
        1. **初始标记 (Initial Mark)**
           - 标记GC Roots能直接关联到的对象
           - 需要Stop-The-World，但时间很短
        2. **并发标记 (Concurrent Mark)**
           - 从初始标记的对象出发，并发地标记所有可达对象
           - 与用户线程并发执行，不需要Stop-The-World
        3. **重新标记 (Remark)**
           - 修正并发标记期间因用户程序继续运行而导致标记变动的那部分对象
           - 需要Stop-The-World，但时间比初始标记稍长
        4. **并发清除 (Concurrent Sweep)**
           - 并发地清理未被标记的对象
           - 与用户线程并发执行
    ## 为什么要分成四步
        1. **减少停顿时间**：将最耗时的标记和清除工作分解并与用户线程并发执行
        2. **准确性与效率的平衡**：
           - 初始标记快速确定直接可达对象
           - 并发标记处理大部分工作但不暂停应用
           - 重新标记确保并发标记期间变化的引用被正确处理
           - 并发清除避免长时间停顿
        3. **并发处理的复杂性**：
           - 在用户线程运行的同时进行垃圾回收需要更精细的控制
           - 分步处理可以更好地管理并发带来的复杂性
        4. **增量式处理**：允许JVM在垃圾回收过程中响应新的分配请求
        这种分步设计使CMS特别适合需要低延迟的应用场景，如Web服务、响应式系统等。

# 46.2 [美团]为啥初始标记和重新标记需要STW？
    在CMS垃圾回收器中，初始标记（Initial Mark）和重新标记（Remark）阶段需要Stop-The-World（STW），主要是为了保证垃圾回收的正确性和一致性。

# 46.3 [美团]什么东西可以当做GCRoot，跨代引用怎么办？
# GC Roots 的定义与跨代引用处理
## 一、哪些对象可以作为 GC Roots？
    GC Roots 是垃圾回收的起点，以下对象通常被视为 GC Roots：
    1. **虚拟机栈中的局部变量**
       - 当前执行方法中的局部变量和参数
       - 每个线程的栈帧中的引用
    2. **方法区中的静态变量**
       - 类的静态字段（static 修饰的变量）
    3. **方法区中的常量引用**
       - 字符串常量池中的引用
       - final 静态常量
    4. **本地方法栈中的 JNI 引用**
       - Java Native Interface 引用的对象
    5. **Java 虚拟机内部引用**
       - 基本类型对应的 Class 对象
       - 常驻异常对象（如 NullPointerException）
       - 系统类加载器
    6. **被同步锁持有的对象**
       - synchronized 持有的对象
    7. **JMXBean 等管理对象**
## 二、跨代引用问题及解决方案
### 1. 什么是跨代引用？
    当年轻代中的对象被老年代中的对象引用时（或者反过来），就产生了跨代引用。例如：
    - 老年代对象持有年轻代对象的引用
    - 年轻代对象持有老年代对象的引用
### 2. 跨代引用带来的问题
    传统垃圾回收算法（如分代收集）需要扫描整个老年代来确定年轻代对象是否存活，这会显著降低性能。
### 3. 解决方案：记忆集（Remembered Set）
    HotSpot JVM 使用记忆集来解决跨代引用问题：
    - **数据结构**：通常是一个卡表（Card Table）
    - **工作原理**：
      1. 将堆划分为若干"卡页"（通常512字节）
      2. 当老年代对象引用年轻代对象时，标记对应的卡页为"脏"
      3. 在年轻代GC时，只需扫描脏卡页而非整个老年代
    - **写屏障（Write Barrier）**：
      - 在对象引用更新时触发的机制
      - 负责维护卡表状态

# 46.6 [美团]如果外部接口的RT无法保证，如何处理？
# 外部接口响应时间(RT)不可靠的处理方案
    当依赖的外部接口响应时间无法保证时，需要采取系统化的容错策略来保障自身服务的可用性和稳定性。以下是完整的解决方案：
## 一、架构设计层面
### 1. 服务隔离
    - **线程池隔离**：为外部调用分配专用线程池，避免拖垮主业务线程
        ```java
        // 示例：Hystrix线程池隔离
        @HystrixCommand(
            threadPoolKey = "externalServicePool",
            threadPoolProperties = {
                @HystrixProperty(name="coreSize", value="20"),
                @HystrixProperty(name="maxQueueSize", value="100")
            }
        )
        public String callExternalApi() {
            // 外部调用逻辑
        }
        ```
    - **信号量隔离**：适合非网络调用的资源保护
        ```java
        @HystrixCommand(commandProperties = {
            @HystrixProperty(name="execution.isolation.strategy", value="SEMAPHORE")
        })
        ```
### 2. 异步化设计
    - **CompletableFuture异步调用**：
        ```java
        CompletableFuture.supplyAsync(() -> externalService.call(), executorService)
            .thenApply(response -> process(response))
            .exceptionally(ex -> fallback());
        ```
    - **事件驱动架构**：使用消息队列解耦
        ```
        [你的服务] --请求--> [消息队列] --消费--> [外部服务适配层]
        ```
## 二、技术实现方案
### 1. 超时控制
    - **多层超时设置**：
          ```java
          // OkHttpClient示例
          OkHttpClient client = new OkHttpClient.Builder()
              .connectTimeout(1, TimeUnit.SECONDS)
              .readTimeout(3, TimeUnit.SECONDS)
              .writeTimeout(2, TimeUnit.SECONDS)
              .build();
          ```
    - **Spring Boot配置**：
          ```yaml
          feign:
            client:
              config:
                default:
                  connectTimeout: 5000
                  readTimeout: 10000
          ```
### 2. 熔断降级
    - **熔断器模式实现**：
        ```java
        @HystrixCommand(
            fallbackMethod = "fallbackMethod",
            commandProperties = {
                @HystrixProperty(name="circuitBreaker.requestVolumeThreshold", value="10"),
                @HystrixProperty(name="circuitBreaker.sleepWindowInMilliseconds", value="10000")
            }
        )
        public String callExternal() { ... }
        public String fallbackMethod() {
            return "缓存数据";
        }
        ```
    - **Resilience4j实现**：
        ```java
        CircuitBreaker circuitBreaker = CircuitBreaker.ofDefaults("externalService");
        Supplier<String> decoratedSupplier = CircuitBreaker
            .decorateSupplier(circuitBreaker, externalService::call);
        ```
### 3. 重试策略
    - **指数退避重试**：
        ```java
        Retryer<Response> retryer = RetryerBuilder.<Response>newBuilder()
            .retryIfException()
            .withWaitStrategy(WaitStrategies.exponentialWait(100, 5, TimeUnit.MINUTES))
            .withStopStrategy(StopStrategies.afterAttempt(3))
            .build();
        ```
### 4. 请求缓存
    - **多级缓存方案**：
        ```
        本地缓存(Caffeine) → 分布式缓存(Redis) → 持久化存储
        ```
    - **Spring Cache示例**：
```java
        @Cacheable(value="externalData", key="#param",
            unless="#result == null || #result.isEmpty()")
        public String getExternalData(String param) { ... }
        ```
## 三、业务保障措施
### 1. 降级方案设计
    - **静态降级**：返回预定义的默认值
    - **动态降级**：返回最近成功的缓存数据
    - **功能降级**：关闭非核心功能分支
### 2. 流量控制
    - **限流算法实现**：
        ```java
        // Guava RateLimiter
        RateLimiter limiter = RateLimiter.create(10.0); // 每秒10个请求
        if (limiter.tryAcquire()) {
            callExternalAPI();
        } else {
            return fallback();
        }
        ```
    - **Sentinel配置**：
        ```java
        @SentinelResource(value = "externalApi",
            blockHandler = "blockHandler",
            fallback = "fallback")
        public String callExternal() { ... }
        ```
### 3. 监控告警
    - **关键指标监控**：
      - 接口P99/P95响应时间
      - 错误率/超时率
      - 熔断器状态
    - **Prometheus + Grafana配置**：
        ```yaml
        - pattern: 'http_client_requests_seconds_(count|sum)'
          name: 'http_client_requests_seconds_$1'
          labels:
            method: '$1'
            uri: '$2'
            status: '$3'
        ```
## 四、运维保障体系
### 1. 服务分级
- **SLA分级**：
  ```
  Tier1 (99.99%) → 核心支付接口
  Tier2 (99.9%) → 商品信息接口
  Tier3 (99%) → 推荐服务接口
  ```
### 2. 压测方案
    - **混沌工程测试**：
      - 模拟网络延迟：`tc qdisc add dev eth0 root netem delay 200ms`
      - 模拟丢包：`tc qdisc change dev eth0 root netem loss 10%`
### 3. 容灾演练
    - 定期演练项目：
      ```
      1. 拔掉数据中心网线
      2. 模拟第三方服务完全不可用
      3. 测试自动切换能力
      ```
## 五、最佳实践建议
    1. **分级超时设置**：
       ```
       连接超时 < 读超时 < 业务超时 < 熔断超时
       ```
    2. **默认值设计原则**：
       - 所有外部依赖都应该有合理的默认返回值
       - 关键路径与非关键路径分离
    3. **技术选型建议**：
       ```
       HTTP客户端：Apache HttpClient → OkHttp → Vert.x WebClient
       熔断框架：Hystrix → Resilience4j → Sentinel
       缓存方案：Caffeine → Redis → Hazelcast
       ```
    4. **监控指标看板**：
       ```
       1. 实时错误率大盘
       2. 依赖拓扑图
       3. 熔断器状态矩阵
       ```
通过以上多维度的解决方案组合，可以构建出健壮的防护体系，即使面对最不稳定的外部接口，也能保证自身服务的稳定运行。实际实施时需要根据业务特点和技术栈进行适当调整。

# 线程池隔离示例：使用Hystrix实现外部调用隔离
下面是一个完整的Java代码示例，演示如何使用Hystrix的线程池隔离功能来保护主业务线程不被外部调用拖垮：
    ```java
    import com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand;
    import com.netflix.hystrix.contrib.javanica.annotation.HystrixProperty;
    import org.springframework.stereotype.Service;
    @Service
    public class ExternalServiceCaller {
        // 主业务方法
        public String processBusinessLogic(String input) {
            // 主业务逻辑处理...
            System.out.println("Processing main business logic with input: " + input);

            // 调用外部服务
            String externalResult = callExternalApi(input);

            // 继续处理业务逻辑
            System.out.println("Continuing main business logic with external result: " + externalResult);
            return "Processed: " + externalResult;
        }
        /**
         * 使用线程池隔离的外部调用方法
         * 配置了专用的线程池(externalServicePool)，核心线程20个，最大队列100
         */
        @HystrixCommand(
            threadPoolKey = "externalServicePool",
            threadPoolProperties = {
                @HystrixProperty(name = "coreSize", value = "20"),
                @HystrixProperty(name = "maxQueueSize", value = "100")
            },
            fallbackMethod = "externalApiFallback"
        )
        public String callExternalApi(String param) {
            // 模拟外部API调用
            System.out.println("Calling external API with param: " + param +
                             " on thread: " + Thread.currentThread().getName());

            // 模拟网络延迟
            try {
                Thread.sleep(500);
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            }
            // 模拟外部API响应
            return "ExternalResponse-";
            }
    }

# 46.10 [美团]公平锁和非公平锁区别是啥？公平锁的缺点？reentrantLock 是如何实现公平锁和非公平锁的？
# 公平锁与非公平锁详解
## 一、公平锁与非公平锁的核心区别
        | 特性        | 公平锁                                     | 非公平锁                                   |
        |-----------|--------------------------------------------|------------------------------------------|
        | **获取顺序** | 严格按照线程请求顺序分配锁                     | 允许插队，新请求线程可能立即获取锁              |
        | **吞吐量**  | 较低                                       | 较高                                      |
        | **饥饿风险** | 无                                        | 可能发生线程饥饿                             |
        | **实现复杂度** | 较高                                     | 较低                                      |
## 二、公平锁的缺点
    1. **性能开销大**
       - 需要维护有序队列
       - 线程切换频繁（唤醒严格按照顺序）
    2. **吞吐量较低**
       - 即使锁可用，也必须检查队列中是否有等待线程
       - 无法利用CPU时间片局部性原理
    3. **响应时间不稳定**
       - 新请求线程必须排队，无法利用锁释放后的短暂空闲期
## 三、ReentrantLock的实现原理
### 1. 底层数据结构
    基于AQS（AbstractQueuedSynchronizer）实现：
    ```java
    public class ReentrantLock {
        private final Sync sync;
        abstract static class Sync extends AbstractQueuedSynchronizer {
            // 实现锁的基本操作
        }
    }
    ```
### 2. 公平锁实现（FairSync）
    ```java
    protected final boolean tryAcquire(int acquires) {
        final Thread current = Thread.currentThread();
        int c = getState();
        if (c == 0) {
            // 关键区别：先检查是否有前驱节点
            if (!hasQueuedPredecessors() &&
                compareAndSetState(0, acquires)) {
                setExclusiveOwnerThread(current);
                return true;
            }
        }
        // 重入逻辑...
    }
    ```
### 3. 非公平锁实现（NonfairSync）
    ```java
    final boolean nonfairTryAcquire(int acquires) {
        final Thread current = Thread.currentThread();
        int c = getState();
        if (c == 0) {
            // 直接尝试CAS获取，不检查队列
            if (compareAndSetState(0, acquires)) {
                setExclusiveOwnerThread(current);
                return true;
            }
        }
        // 重入逻辑...
    }
    ```
### 4. 关键差异图示
    公平锁流程：
        [新线程] → 检查队列 → [有等待线程?加入队列尾部 : 尝试获取锁]
    非公平锁流程：
        [新线程] → 直接尝试获取锁 → [失败?加入队列尾部]
## 四、选择建议
    1. **用非公平锁当**：
       - 追求高吞吐量
       - 锁持有时间较短
       - 能容忍偶尔的线程饥饿
    2. **用公平锁当**：
       - 需要严格按顺序执行
       - 防止优先级反转
       - 锁持有时间较长且间隔均匀
## 五、性能对比数据
    典型基准测试结果（仅供参考）：
    - 高竞争场景：
      - 非公平锁吞吐量比公平锁高30-50%
    - 低竞争场景：
      - 两者性能差异小于10%
## 六、实现细节注意点
    1. **AQS队列管理**：
       ```java
       // 公平锁的关键检查方法
       public final boolean hasQueuedPredecessors() {
           Node h, s;
           return ((h = head) != null &&
                  (s = h.next) != null &&
                  s.thread != Thread.currentThread());
       }
       ```
    2. **锁重入实现**：
       ```java
       // 在Sync类中
       if (current == getExclusiveOwnerThread()) {
           int nextc = c + acquires;
           if (nextc < 0) throw new Error("Maximum lock count exceeded");
           setState(nextc);
           return true;
       }
   ```
    3. **性能优化技巧**：
       - 非公平锁通过两次CAS尝试减少入队概率
       - 队列头节点唤醒后可能与新请求线程竞争
    理解这些差异有助于根据实际业务场景做出最佳选择。在大多数情况下，非公平锁的默认实现已经能提供很好的性能表现。

# 46.11 [美团]Mysql的行级锁到底锁的是什么东西？
# MySQL行级锁的锁定对象详解
    MySQL的行级锁实际上并不是直接锁定物理行数据，而是通过锁定索引记录来实现的。理解这一点对正确使用和优化MySQL锁机制至关重要。
## 一、行级锁的锁定对象
### 1. 锁定的是索引记录而非物理行
    - **对于主键索引**：直接锁定主键索引上的记录
    - **对于二级索引**：先锁定二级索引记录，再锁定对应的主键索引记录
    - **无索引情况**：会退化为表锁（实际锁定所有行）
### 2. 不同行锁类型的锁定内容
    | 锁类型         | 锁定内容                                                                 |
    |----------------|--------------------------------------------------------------------------|
    | **记录锁(Record Lock)** | 锁定索引中的单条记录                                                     |
    | **间隙锁(Gap Lock)**   | 锁定索引记录之间的间隙（防止幻读）                                        |
    | **临键锁(Next-Key Lock)** | 记录锁+间隙锁的组合（锁定记录及前面的间隙）                                |
    | **插入意向锁(Insert Intention Lock)** | 特殊的间隙锁，表示准备插入                                              |
## 二、实际锁定机制分析
### 1. 不同索引情况下的锁定示例
**表结构示例**：
    ```sql
    CREATE TABLE `users` (
      `id` int PRIMARY KEY,
      `name` varchar(20),
      `age` int,
      KEY `idx_age` (`age`)
    );
    ```
#### 场景1：使用主键索引
    ```sql
    -- 会话1
        BEGIN;
        SELECT * FROM users WHERE id = 5 FOR UPDATE;
        -- 锁定id=5的主键索引记录
    -- 会话2（被阻塞）
        UPDATE users SET name = 'test' WHERE id = 5;
        ```
#### 场景2：使用二级索引
    ```sql
    -- 会话1
        BEGIN;
        SELECT * FROM users WHERE age = 20 FOR UPDATE;
        -- 锁定idx_age索引中age=20的记录，同时锁定对应主键记录
    -- 会话2（被阻塞）
        UPDATE users SET name = 'test' WHERE age = 20;
        -- 会话3（可能被阻塞，取决于主键值）
        INSERT INTO users VALUES (X, 'new', 20);
        ```
#### 场景3：无索引情况
    ```sql
        -- 会话1
        BEGIN;
        SELECT * FROM users WHERE name = 'John' FOR UPDATE;
        -- 没有name索引，退化为表锁
    -- 会话2（所有操作都会被阻塞）
        INSERT INTO users VALUES (10, 'Mike', 30);
        ```
### 2. InnoDB锁的实现层次
    1. **内存中的锁结构**：每个事务维护一个锁请求列表
    2. **索引记录标记**：在索引记录上设置锁定标记
    3. **等待队列**：冲突的锁请求进入等待状态
## 三、特殊锁定情况
### 1. 唯一索引与非唯一索引的区别
    - **唯一索引**：仅需要记录锁（因为值唯一）
    - **非唯一索引**：需要临键锁防止幻读
### 2. 外键约束的锁定
    - 父表更新时会锁定子表相关记录
    - 子表插入时需要检查父表记录
### 3. 自动递增锁
    - 特殊的表级锁，用于保证自增ID连续性
## 四、查看锁信息的实用命令
    1. 查看当前锁情况：
    ```sql
    SHOW ENGINE INNODB STATUS\G
    -- 查看LATEST DETECTED DEADLOCK部分
    ```
    2. 性能库中的锁信息：
        ```sql
        SELECT * FROM performance_schema.data_locks;
        SELECT * FROM performance_schema.data_lock_waits;
        ```
    3. 查看锁等待：
        ```sql
        SELECT * FROM sys.innodb_lock_waits;
        ```
## 五、优化建议
    1. **合理设计索引**：确保查询使用合适的索引
    2. **控制事务大小**：减少锁持有时间
    3. **使用较低的隔离级别**：如READ COMMITTED可减少间隙锁
    4. **避免无索引更新**：防止意外表锁
    5. **使用锁超时**：
    ```sql
    SET innodb_lock_wait_timeout = 5; -- 设置锁等待超时为5秒
    ```
理解MySQL行级锁的真实锁定对象可以帮助开发者避免死锁、提高并发性能，并正确设计数据库访问模式。

# 46.17 [阿里]如何实现一个类加载器？为什么是LoadClass而不是findClass？
# 实现类加载器及 loadClass 与 findClass 的区别
## 一、如何实现自定义类加载器
### 1. 基本实现步骤
    ```java
    public class MyClassLoader extends ClassLoader {
        private String classPath;

        public MyClassLoader(String classPath) {
            this.classPath = classPath;
        }

        @Override
        protected Class<?> findClass(String name) throws ClassNotFoundException {
            try {
                // 1. 获取类文件字节码
                byte[] classData = getClassData(name);
                // 2. 定义类对象
                return defineClass(name, classData, 0, classData.length);
            } catch (IOException e) {
                throw new ClassNotFoundException(name);
            }
        }

        private byte[] getClassData(String className) throws IOException {
            // 转换类名路径：com.example.Test -> com/example/Test.class
            String path = classPath + File.separatorChar +
                         className.replace('.', File.separatorChar) + ".class";
            try (InputStream ins = new FileInputStream(path);
                 ByteArrayOutputStream baos = new ByteArrayOutputStream()) {
                byte[] buffer = new byte[4096];
                int bytesNumRead;
                while ((bytesNumRead = ins.read(buffer)) != -1) {
                    baos.write(buffer, 0, bytesNumRead);
                }
                return baos.toByteArray();
            }
        }
    }
    ```
### 2. 使用示例
    ```java
    public class Main {
        public static void main(String[] args) throws Exception {
            MyClassLoader loader = new MyClassLoader("D:/myclasses");
            Class<?> clazz = loader.loadClass("com.example.Demo");
            Object obj = clazz.newInstance();
            System.out.println(obj.getClass().getClassLoader());
        }
    }
    ```
## 二、为什么重写 findClass 而不是 loadClass
### 1. 双亲委派模型流程
    ```
    loadClass(String name, boolean resolve)
      └─ findLoadedClass(name)       // 检查是否已加载
         └─ parent.loadClass(name)   // 委托父加载器
            └─ ... (递归向上委托)
               └─ findClass(name)   // 最终调用自己的findClass
    ```
### 2. 关键区别
    | 特性                | loadClass                          | findClass                          |
    |---------------------|-----------------------------------|-----------------------------------|
    | 默认实现            | 包含完整双亲委派逻辑               | 直接抛出ClassNotFoundException    |
    | 重写影响            | 可能破坏双亲委派机制               | 保持双亲委派完整性                |
    | 主要职责            | 类加载流程控制                     | 实际类加载实现                    |
    | 是否调用defineClass | 否（由findClass调用）             | 是                                |
    | 典型使用场景        | 需要打破双亲委派时                 | 标准自定义类加载器实现            |
### 3. 核心原因
    1. **架构清晰性**：`loadClass`处理流程控制，`findClass`处理具体加载逻辑
    2. **安全性保障**：避免自定义加载器绕过父类加载器检查
    3. **维护双亲委派**：默认`loadClass`实现已经包含规范的委派逻辑
    4. **扩展友好性**：只需关注如何获取类字节码，不用重复实现委派逻辑
### 4. 需要重写loadClass的特殊情况
    当需要**打破双亲委派模型**时（如热部署、模块化加载）：
    ```java
    @Override
    protected Class<?> loadClass(String name, boolean resolve)
        throws ClassNotFoundException {
        // 1. 检查特定包下的类自行加载
        if (name.startsWith("com.myapp.")) {
            return findClass(name);
        }
        // 2. 其他类仍走双亲委派
        return super.loadClass(name, resolve);
    }
    ```
## 三、最佳实践建议
    1. **优先重写findClass**：99%的场景只需重写findClass
    2. **保持双亲委派**：除非明确需要打破该模型
    3. **注意类卸载**：自定义类加载器加载的类在 loader 被回收时才能卸载
    4. **线程安全**：ClassLoader的方法需要保证线程安全
    5. **资源释放**：及时关闭文件流等资源
    通过这种设计，Java既保持了类加载的安全性，又为开发者提供了足够的扩展灵活性。

# 46.24 [腾讯]热点商家交易订单的写入如何处理？
# 热点商家交易订单的写入处理方案
    处理热点商家(高频交易商家)的订单写入是一个常见的分布式系统挑战。以下是几种有效的处理方案：
## 1. 数据分片(Sharding)
    - **按商家ID分片**：将不同商家的订单分散到不同的数据库分片或表中
    - **时间维度分片**：结合时间范围进行分片(如按天/月分表)
    - **组合分片键**：使用商家ID+时间戳等组合作为分片键
## 2. 缓存层设计
    - **写入缓存队列**：使用Kafka/RocketMQ等消息队列缓冲写入请求
    - **内存缓存**：Redis集群暂存热点订单，异步批量写入数据库
    - **多级缓存**：本地缓存+分布式缓存组合
## 3. 数据库优化
    - **读写分离**：主库处理写入，从库处理查询
    - **数据库垂直/水平拆分**：订单库独立部署，避免与其他业务竞争资源
    - **NoSQL辅助**：对非核心数据使用MongoDB等文档数据库
## 4. 限流与降级
    - **请求限流**：对热点商家接口实施令牌桶/漏桶限流
    - **服务降级**：高峰时段关闭非核心功能(如复杂统计)
    - **熔断机制**：当系统压力过大时暂时拒绝部分请求
## 5. 异步处理
    - **最终一致性**：先记录订单基础信息，其他处理异步完成
    - **事件驱动架构**：通过事件总线触发后续处理流程
    - **批处理写入**：合并短时间内的多个写入操作
## 6. 架构设计建议
    - 采用微服务架构，订单服务独立部署
    - 实施服务网格治理，动态调整热点商家资源分配
    - 使用分布式事务框架保证数据一致性(如Seata)
    实际应用中，通常需要组合多种方案，并根据业务特点进行定制化设计。

# 46.25 [腾讯]和外部机构的API交互如何防止外部机构服务不可用拖垮调用服务
# 防止外部API服务不可用拖垮调用服务的策略
当与外部机构API交互时，服务不可用可能导致级联故障。以下是几种有效的防护策略：
## 1. 超时控制
    - 设置合理的连接超时和读取超时
    - 根据API特性调整超时时间（通常连接超时1-3秒，读取超时5-30秒）
    - 避免无限等待阻塞系统资源
## 2. 熔断机制
    - 实现熔断器模式（如Hystrix、Resilience4j）
    - 当错误率达到阈值时自动切断请求
    - 设置合理的恢复时间窗口
## 3. 限流措施
    - 实现请求速率限制
    - 使用令牌桶或漏桶算法控制请求频率
    - 为不同优先级API设置不同限流策略
## 4. 异步调用
    - 使用消息队列解耦同步调用
    - 将请求放入队列后立即返回
    - 后台处理队列中的请求并重试
## 5. 缓存策略
    - 对可缓存的数据实现本地缓存
    - 使用多级缓存（内存缓存、分布式缓存）
    - 设置合理的缓存过期策略
## 6. 优雅降级
    - 准备默认返回值或简化逻辑
    - 当外部服务不可用时自动切换降级方案
    - 确保核心功能仍可运行
## 7. 重试策略
    - 实现指数退避重试机制
    - 限制最大重试次数
    - 对非幂等操作谨慎使用重试
## 8. 监控与告警
    - 实时监控API调用成功率、延迟等指标
    - 设置合理的告警阈值
    - 快速响应服务异常
## 9. 负载测试
    - 定期进行压力测试了解系统极限
    - 模拟外部服务延迟和故障场景
    - 验证防护机制的有效性
    通过综合应用这些策略，可以有效隔离外部服务故障，保护自身系统的稳定性。

# 46.26 [腾讯]微信运动排行榜如何设计
    详见：demo-mybatis-plus18/doc/微信运动排行榜如何设计.md









